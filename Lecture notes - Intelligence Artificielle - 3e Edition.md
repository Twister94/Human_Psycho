MOC : [[05_MOOC/LECTURE -  PROGRAMMATION MOC]]
Intelligence Artificielle - 3e Edition - Structure du livre 

Source : 
Auteur : 
Date de création : 
Tags : #Programmation #IA

Notes liées :
[[Python]] [[C]]
***




# Partie I : Intelligence Artificielle

## Chapitre 1 : Introduction
### Définition de l'IA 

#### Agir commes des humains : le test du Turing

Mots-clefs : Traitement du langage naturel, représentation des connaissances, raisonnement automatisé, l'apprentissage, test de Turing (complet ou non), vision artificielle, robotique

#### Penser comme des humains : l'approche cognitive

Mots-clefs : Sciences cognitives 

#### Penser rationnellement : les "lois de la pensée"

Mots-clefs : Syllogismes, logistice

#### Agir rationnellement : L'approche de l'agent rationnel
 
Mots-clefs : Agent (rationnel), rationalité limité



### Fondements de l’intelligence artificielle

#### Philosophie 

Mots-clefs : Rationalisme, dualisme, matérialisme, empiriste, induction, positivisme logique, faits d'observation, théorie de la confirmation

#### Mathématiques

Mots-clefs : Algorithme, théorème d'incomplétude, fonctions calculables, praticabilité, NP-complétude, probabilités

#### Economie 

Mots-clefs : Théorie de la décision, théorie des jeux, jeu, recherche opérationnelle, les processus de décision de Markov, le choix le plus satisfaisant

#### Neurosciences 

Mots-clefs : Neurosciences, neurones, singularité

#### Psychologie 

Mots-clefs : béhabioriste, psychologie cognitive, sciences cognitives

#### Ingénierie informatique

Mots-clefs :

#### Théorie du contrôle et cybernétique

Mots-clefs : Théorie du contrôle (ou théorie de la commande), dispositifs héméostatiques, fonction objectif


#### Linguistique
Mots-clefs : Representation des connaissances, Traitement du langage naturel (linguistique computationelle)


### Histoire de l'intelligence artificielle 
#### Gestion de l'intelligence artificielle

Mots-clefs : Apprentissage hebbien

#### Naissance de l'intelligence artificielle

Mots-clefs :

#### L'enthousiasme des débuts : les grandes espérences (1952 - 1969)

Mots-clefs : Système symbolique matériel, réseaux adalines, perceptrons, théorème de convergence du perceptron

#### L'épreuve de la réalité (1966 -1973)

Mots-clefs : Algorithmes génétiques (évolution artificielle),  

#### Systèmes fondés sur les connaissances (1969 - 1979) : la clé de la puissance

Mots-clefs : Méthodes faibles, systèmes experts, facteurs de certitude, schémas.


#### L'IA devient une industrie (de 1980 à nos jours)

Mots-clefs : rétroprogration, connexionnistes

#### Retour des réseaux de neurones (de 1986 à nos jours)

Mots-clefs : 

#### L'IA devient une science (de 1987 à nos jours)

Mots-clefs : 

#### Emergence des agents intelligents (de 1995 à nos jours)

Mots-clefs : IA de niveau humain, intelligence articificielle générale, IA amicale.

####  La disponibilité de vastes ensembles de données (de 2001 à nos jours)

Mots-clefs :

### Etat de l’art 
Mots-clefs : Véhicules autonomes, Reconnaissance de la parole, Plannification et programmation autonome, Jeux, anti-spam. Planification logisitique, Robotique. Traduction automatique.



### Résumé
***
 
## Chapitre 2 : Agents intelligents

### Agents et environnements 

Mots-clefs : Agent rationnels, intelligents, agent, environnement, capteurs, effecteurs. Percepts, séquence des percepts, fonction agent, programme agent. Mesure de performance

### Bons comportements : le concept de rationalité 

#### Rationalité

Mots-clefs : Définition d'un agent rationnel 

#### Omniscience, apprentissage et autonomie

Mots-clefs : Omniscience, collecte d'informations, exploration, apprendre


### Nature des environnements 

#### Spécification de l'environnement d'une tâche

Mots-clefs : Environnements des tâches, Environnements de la tâche, PEAS, mesure de performance, environnement. Effecteurs. Capteurs, agents logiciels (softbots)

#### Propriétes des environnements de tâches

Mots-clefs : Entièrement observable, partiellement observable, inobservable, monoagent, multi-agent, concurrentiel, coopératif, communication, comportement aléatoire, déterministe stochastique, épisodique, séquentiel, incertain, non déterministe.
Statique, dynamique, semi-dynamique, discret, continu, connu, inconnu, classe d'envrionnements, génerateur d'environnements. 

### Structure des agents  
 
 
 
#### Programmes agents

Mots-clefs : Programme agent, architecture

#### Agents réflexes simples 

Mots-clefs : Agent réflexe simple, règle condition-action

#### Agents réflexes fondés sur des modèles

Mots-clefs : Modèle, agent fondé sur un modèle

#### Agents  fondés sur des buts 

Mots-clefs : Exploration, plannification

#### Agents  fondés sur l'utilité

Mots-clefs : Utilité, fonction d'utilité, utilité espérée 

#### Agents capables d'apprentissage

Mots-clefs : Module d'apprentissage, module de performance, critique, générateur de problèmes, récompense ou pénalité


#### Fonctionnement interne des programmes agents 

Mots-clefs : atomique, factorisée et structurée, représentation atomique, exploration, jeu à deux joueurs, modèles de Markov cachés, processus de décisions de Markov, représentation factorisée, variables, attributs, logique propositionelle, satisfaction des contraintes, réseaux bayésiens, algorithmes d'apprentissage, représentation structurée, bases de données relationnelles, logique du premier ordre, modèles probabilistes du premier ordre, l'apprentissage fondée sur la connaissance, compréhension du langage naturel, expressivité


 
 ## Résumé
 
 
 
# Partie II : Résolution de problèmes
***

## Chapitre 3 : Résolution des problèmes par l’exploration 

Mots clefs :  Agent de résolution de problèmes, agents de planification, factorisée, structure, problèmes, solutions, non informés, informés, 


### Agents de résolution de problèmes 

#### Problèmes et solutions bien définis

Mots-clefs : But, formulation du but, formulation du problème, inconnu, observable, discret, connu, déterministe, exploration, solution, execution, boucle ouverte, problème, état initial, actions, applicable, modèle de transition, successeur, espace des états, graphe, chemin, test de but, coût de chemin, coût de l'étape, solution, solution optimale, abstraction. Un problème jouet, problème du monde réel, monde de l'aspirateur, Etats, Etat initial, actions, modèle de transition, test du but, Coût de chemin, taquin à 8 pièces, Etats, Etat initial, actions, modèle de transition, test du but, coût du chemin, puzzles à glissement de pièces, problème des 8 reines, formulation incrémentale,  formulation complète, Etats, Etat initial, actions, modèle de transition, Etats, actions



#### De la formulation des problèmes

Mots-clefs :



### Exemples de problèmes 

#### Problèmes jouets

Mots-clefs :

#### Problème du monde réel

Mots-clefs : Problème de recherche d'un trajet, problèmes de tournées, problème du voyageur de commerce, problème d'agencement de VLSI, ou problème de placement-routage, le placement des cellules et le routage des connexions. Navigation d'un robot, l'ordonnancement automatique de l'assemblage, conception de protéines de synthèse.


### Recherche de solutions 

Mots clefs : Arbre d'exploration, les noeuds, développant, génère, noeud parent, noeuds fils, noeud feuille, liste ouverte, frontière, stratégies d'exploration, état répétée, chemin avec boucle, chemins redondantes, grille rectangulaire, ensemble explorée (ou liste fermée), sépare, file, file de priorité, FIFO, LIFO, pile, forme canonique, Complétude, optimalité, complexité en temps, complexité en espace. Le facteur de branchement, la profondeur, coût de l'exploration, coût total

Exploration non informée (aveugle), exploration informée, exploration heuristique, exploration en largeur d'abord

Exploration à cout uniforme

Exploration en profondeur d'abord, exploration avec retour arrière

Exploration en profondeur limitée, exploration itérative par allongement (ILS)

Exploration bidirectionnelle, Prédécesseurs

exploration informée, fonction d'évaluation, exploration par le meilleur d'abord, fonction heursitique

Exploration gloutonne par le meilleur d'abord, distance à vol d'oiseau, 

Exploration A étoile, heuristique admissible, consistance, monotonie, inégalité triangulaire, contours, élagué, optimalement efficace, erreur absolue, erreur relative, 

A étoile avec approfondissement itératif (IDA*), exploration récursive par le meilleur d'abord, valeur rapportée, MA*, SMA*, thrashing, espace des états de métaniveau, espace des états de niveau objet, coût total, distance city-block, distance Manahattan, 

Facteur de branchement, domine, 

Problème relaxé, consistance

Sous-problème, bases de données de motifs, bases de données de motifs disjoints


Exploration locale, recuit simulé, algorithmes génétiques, évantualité,  recherche en ligne, exploration locale, noeud courant, problème d'optimisation, fonction objectif, paysage de l'espace des états minimum global, maximum global, complet, optimal. 

Exploration par escalade (hill-climbing), plus forte pente, problème des huits reines, formulation à états complets. Exploration locale gloutonne

Maxima locaux, crêtes, Plateaux, palier, déplacement latéral. Escalade stochastique, escalade du premier choix, escalade avec reprise aléatoire, 

Recuit simulé, recuit,  descente de gradient, exploration locale en faisceau, exploration en faisceau stochastique. Algorithme génétique, population, individu, fonction d'adaptation, recombination, mutation, 

discrétiser, variables, gradient, pas de l'étape, gradient empirique, exploration linéaire, Newton-Raphson, Hessienne, optimisation, sous contraintes, convexe, programmation linéaire, 

plan contigent, statégie,

Monde aspirateur capricieux, modèle de transition,  solution, 

noeuds, entrelacement, 

solution cyclique, 

etat de croyance,

Sans capteur, conformant

contraindre, états de croyance, état initial, actions, modèle de transtion, test de but, coût de chemin, 

Exploration incrémentale des états de croyance, 

Prévision, prévision d'observation, mise à jour, 

évaluation d'état, surveillance, filtrage, récursif, localisation, 

Exploration hors ligne, exploration en ligne, entrelaçant, problème de découverte

Ratio de compétitivité, irréversibles, impasse, argument adverse, explorable sans risque

Exploration par escalade, parcours de aléatoire, LRTA*, optimisme sous incertitude

environnements multiagents, contingences, concurrentiels, exploration en situation d'adversité
la théorie mathématique des jeux, somme nulle, information parfaite, 
Elagage, fonction d'évaluation information imparfaite, état initial, états terminaux, fonction d'utilité 
Jeu à somme nulle, arbre du jeu, arbre d'exploration, stratégie, tour, valeur minimax, décision minimax, algorithme minimax, remonter, 

Elagage alpha-béta, alliances, coups de maître, transpositions, table de transpositions, fonction d'évaluation, test d'arrêt (cut off test)

Attributs, valeurs attendues, fonction linéaire pondérée, positions stables, recherche de stabilité, effet horizon, extension de singularité, Elagage en avant, exploration en faisceau, rétrograde, politique, rétrograde, jeux stochastiques, noeuds de hasard, valeur espérée, valeur minimax, valeur minimax espérée

SImulation de Monte-Carlo, observabilité partielle, kriegspiel, état de croyance, estimation des états, stratégie, mat garanti, mat probabiliste, mat accidentel, équilibre, bluff,  Echecs, coup nul, élagage par inanité, Jeu de  dames, Othello, Backgammon, go, des jeux combinatoires, théorie, bridge, impasses et le squezze, généralisation fondée sur des explications, Scrabble

Etats, Representation factorisée, problème à satisfaction de Contraintes, assignation, cohérente, assignation complète, solution, assignation partielle

graphe de contraintes, 

Contraintes de priorité, contraintes disjointives, discrètes, domaines discrets, domaine infini, langage de contraintes, contraintes linéaires, contraintes non linéaires, domaines continus, programmation linéaire, contrainte unaire, contrainte binaire, contrainte globale, cryptaritmétique.

Variables auxiliaires, hypergraphe des contraintes, graphe biparti, absolues, contraintes de préférence, problème à optimisation de contraintes.

Inférence, progagation de contraintes, cohérence locale, noeud-cohérente, arc-cohérente, arc-cohérente généralisé, cohérence de chemin, k-cohérence, fortement k-cohérent, contrainte globale, contrainte de ressources, propagation de limites, limite-cohérent X, Sudoku, unité, commutativité, exploration avec backtracking. L'heuristique du minimum de valeurs restantes.
Heuristique des degres, valeur la moins contraingnante, forward checking, maintien de la cohérence d'arc, backtracking chronologique, ensemble de conflit, backjumping, backjumping orienté conflit, apprentissage de contraintes, variables inutiles, min-conflits, exploration taboue, pondération de contraintes, sous-problèmes indépendants, composantes connexes, arbre, cohérence d'arc dirigée, tri topologique, ensemble coupe-cycle, conditionnement du coupe-cycle, décomposition en arbre, largeur d'arbre, contrainte de rupture de symétrie

Raisonnement, Representation, agents fondés sur les connaissances, logique, logique propositionelle, logique du premier ordre, base de connaissances, énoncés, langage de représentation des connaissances, axiome, inférence, connaissances générales, niveau de connaissances, niveau de l'implémentation, déclarative, procédurale, le monde du wumpus,  mesure de performance, environnement, effecteurs, capteurs, 

Syntaxe, sémantique, monde possible, modèle, satisfait, est un modèle de alpha. Conséquence
inférence logique, vérification de modèles, préserve la validité, la vérité. La complétude,fondement, apprentissage, relation de conséquence, logique propositionnelle, syntaxe, énoncés atomiques, symbole propositionnel. Enoncés complexes, connecteurs logiques, négation, littéral positif, littéral négatif, conjonction, termes conjonctifs, disjonction, termes disjonctifs, implication, prémise (antécédent), conclusion, conséquence, règles, si-alors, double-implication.

Table de vérité, valide,  complet, démonstation de théorèmes, équivalence logique, tautologies, théorème de la déduction, satisfiabilité, réfutation, contradiction, 

Règle d'inteférences, preuve, modus ponens (mode qui affirme), élimination de la conjonction, monotonie

Résolution, résolvant, résolution unitaire, littéraux complémentaires, clause unitaire, résolution, factorisation, forme normale conjonctive CNF, clôture par résolution, théorème de résolution propositionelle

clause définie, clause de Horn, clauses buts, corps, fait, tête, chainage avant, chainage arrière, programmation logique, valide, complet, point fixe, pilotée par les données, raisonnement piloté par but

Algorithme de Davis-Putnam, symbole pur, clause unitaire, propagation unitaire, analyse des composants, composants, ordre des variables et des valeurs, l'heuristique des dégrés, bactracking intelligent, apprentissage des clauses conflictuelles, reprises aléatoires, indexation intelligente

Sous-contraint, conjecture du seuil de satisfiabilité, fluent, variables atemporelles, modèle de transition, axiomes d'effet, problème de la persistance, axiomes de persistance. Problème représentationnel de la persistance. Localité, problème inférentiel de la persistance, axiome de l'état sucesseur, problème de la qualification, agent hybride, mettre en cache, état de croyance, estimation des états, approximation conservatrice, axiomes d'exclusion d'action

Logique du premier ordre 

Nature déclarative, compositionnalité, communication, contexte, ambiguite, hypothese de Sapir-Whorf

objets, relations, fonctions, propriétés, logique de premier ordre, position ontologique, modèles, logique floue, degré de vérité, logique d'ordre supérieur, positions épistémologiques, théorie des probabilités

Elements du domaine, domaine, fonctions totales

Symboles de constantes, symboles de prédicats, symboles de fonctions, arité, interprétation, interprétation intentionnelle

terme, terme composé, énoncés atomique, atome, vrai, connecteurs logiques

Quantificateur, terme fermée, interprétations étendues

Symbole d'égalite, 

Hypothèse des noms uniques, hypothèse du monde clos, fermeture du domaine, sémantique des bases de données

assertions, requêtes, buts, substitution, listes des liaisons, axiome, définitions, théorèmes, nombres naturels, axiomes de Peano, infixe, préfixe, sauce syntaxique, ensemble , listes, 

perception, 

Ingéniere des connaissances, acquisition des connaissances, ontologie

Unification, chainage avant, bases de données déductives, systèmes de production, chainage arrière, programmation logique, démonstration de théorèmes, 

Instanciation universelle, terme fermée, instanciation existentielle, constante de Skolem, skolémisation, inférentiellement équivalent, propositionalisation, unification, unificateur, normalisant séparément, unificateur plus général, contrôle des occurences, indexation des prédicats, treillis de subsomptions, Dataog

renomage,point fixe, valide, complet 

Appariement de motifs, ordonnacement des termes conjonctifs, minimum de valeurs restantes, compléxité des données, 

algorithme rete, système de production, architectures cognitives, base de données déductives, ensemble magique, 

chainage arrière, programmation logique, générateur, Prolog, contrôle des occurences, points de choix, pile de restauration (trail), continuations, parralléllisme ou ,parralléllisme et , incomplet, programmation dynamique, mémoisation, programmation logique tabulée, domaines finis, complétion, programmation Logique avec contraintes, métarègles, Resolution, forme normale conjonctive, élimination des implications, déplacement des vers l'intérieur, normalisation des variables, skolémisation, fonction de skolem, suppression des Quantificateurs universels, distribution de sur, 

Resolvante, résolution binaire, factorisation, 

Théorème de résolution propositionelle, lemme de généralisation, Univers de Herband, Saturation, Base de Herband, théorème de Herband, cloture par résolution, 

Démodulation, paramodulation, unification équationnelle,

Préférence pour les clauses unitaires, clause unitaire, résolution unitaire, Ensemble support, résolution dirigée par les entrées, modus ponens, subsomption, synthèse, vérification, synthèse déductive


Planification, représentation factorisée, PDDL, état, sémantique des bases de données, schéma d'action, élargie, précondition, effet, applicable, propositionnaliser, delete list, liste de suppression, add list, état initial, but

Etats pertinents, renommé, applicables, renommés, heuristique admissible, problème relaxé, heuristique d'effacement des préconditions, couverture des arêtes d'un graphe, état abstrait, décomposition, bases de donnés de motifs 

graphe de plannification, niveausx, action de persistance, exclusion mutuelle, mutex, niveau de stabilisation, 
Effets incompatibles, interférence, besoins concurents, coût de niveau, graphe de plannification séquentiel, niveau maximal, somme des niveaux, niveau de réalisation
Effets incompatibles, réalisation incompatible, besoins concurents, pas bonne, 

Les littéraux se croissent de facçon monotone, les actions se croissent de façon monotone

Propositionnaliser les actions, définir l'état initial, propositionnaliser le but, ajouter des axiomes successeurs d'état, ajouter des axiomes de précondition, ajouter des axiomes d'unicité des actions, calcul situationnel, situation, fluent, axiome de possibilité, axiome successeur d'état, axiomes d'unicité des actions, 

faille, moindre compromission

Ordonnancement, problème d'ordonnacement d'atelier, tâches, durée, actions, consommable, réutilisable, makespan, agrégation

méthode du chemin critique, chemin, chemin critique, marge, ordonnancement, marge minimale, décomposition hiérarchique, réseaux hiérarchisés de tâches HTN, actions primitives, action de haut niveau, affinements, récursif, implémentation, 

Propriéte d'affinement descendant, non déterministe, non-déterministe démoniaque, non-déterministe angélique, ensemble atteignable, description optimiste, description pessimiste, exploration en avant hiérarchique, plannification sans capteurs, planification conformante, planification avec contingence, plannification en ligne, replanification, états de croyance, schéma de percept, forcage, 

hypothèse du monde clos, hypothèse du monde ouvert, effet conditionnel, quand condition:effet, approximation conservatrice, précondition manquante, monitoring de l'éxecution, effet manquant, variable d'état manquante, événements exogènes, monitoring des actions, monitoring du plan, monitoring du but, fortuite (serendity) 

apprendre, problème de plannification multiagent, plannification multieffecteur, multicorps, planification décentralisée, coordination, inciateurs, acteur, multiacteur, synchronisation, action commune, faiblement couplés, plan commun liste d'action concurrentes, axiome d'exclusion d'action, convention, lois sociales, communication, reconnaissance de plans, comportement émergent


ontologie supérieure
Catégories, reifier, sous-catégorie, héritage, heritent, taxonomie, hiérarchie taxonomique, disjontes, décomposition exhaustive, partition, Objets composites, assortiment, minimisation logique, mesures, fonction unités, physique qualitative, individualisation, matière , noms comptables, count nouns, noms  non comptables, noms massifs, intrinsèques, extrinsèques, calcul d'évenements, évenements discrets, processus, évenements liquides, susbstances temporelles, substances spatiales, attitudes propositionnelles, transparence référentielle, logique modale, K opérateur modal du savoir, modèle, mondes possibles, relations d'accessibilités, K

Réseaux sémantiques, logiques de description, graphes existentiels, héritage multiple, Programmation orienté objet, attachement procédural, valeurs par défaut, redéfine, logiques de description, subsomption, classsification, cohérence, monotonie, non monotone, logiques non monotone, circonscription, circonscript, modèle préféré, circonscription avec priorité, logique des défauts, règles par défaut, extension, révision des croyances, systèmes à maintenance de vérité, JTMS, justification,  mise à jour des croyances, filtrage, AMTS, explications, hypothése

synonymie, ambiguite, attachement prodécural, wrappers, donimé

Incertitude, état de croyance, problème de la qualification, décision rationnelle, paresse, ignorance théorique, ignorance pratique, degré de croyance, théorie des probabilités, engagement épistémologique, engagement ontologique,  subsumer, synthétiser, préférences, résultats, théorie de l'utilité, utilité, théorie de la décision, maximum de l'utilité espérée, univers, modèle probabiliste, évenements, probabilités inconditionnelles, probabilités a priori, observation, probabilité conditionnelle, probabilité a posteriori, règle du produit, représentation factorisée, variables aléatoires, domaine, P, distribution de probabilités, densité de probabilité, distribution de probabilités conjointe, distribution de probabilités conjointe complète, axiomes de Kolmogorov, fréquentiste, objectiviste, subjectiviste, classe de référence, principe d'indifférence, logique inductive, inférence probabiliste, probabilité marginale, marginalisation, conditionnement, constante de normalisation, indépendence, indépendence marginale, indépendence absolue, règle de Bayes, direction causale, direction diagnostique, diagnostic, indépendence, indépendence conditionnelle, explosion combinatoire, sépare, classificateur bayésien, bayes idiot, 

Réseaux bayésiens, réseau de croyances, réseau probabiliste, réseau causal, carte de connaissances, réseau de décision, diagramme d'influence, modèle graphique, tables de probabilités conditionnelles, cas de conditionnement

règle de chainage, localement structurés (non denses), modèle causal, modèle diagnostique, non-descendants, d-séparation, sa couverture de Markov, distribution canonique, noeuds déterministes, bruitées, relation OU-bruité, noued de fuite, discrétisation, paramètres, non paramétrique, réseau bayesien hybride, linéaire gausienne, gaussienne conditionnelle, distribution probit, distribution logit, fonction sigmoide, variable de requête, variables cachés, élimination des variables, facteur, produit terme à terme, simplement connectés ou polyarbres, multiplements connectés, largeur de l'arbre, algorithme de groupement (join-tree), algorithme de Monte-Carlo, 

échantilonnage pa rejet, cohérente, pondération par la vraisemblance, échantillonage par importance, échantillonage de Gibbs, probabilité de transition, chaine de Markov, distribution stationnaire, ergodique, équilibre détaillé, pour chaque Zi dans Z faire, 

Sémantique des bases de données, hypothese des noms uniques, fermeture du domaine, modèles probabilistes relationnels, incertitude d'existence, incertitude d'identité, typage, indépendence contextuelle, multiplexeur, incertitude relationnelle, dépliement, propositionalisation, fonction d'origine, incertitude à base de règles, ignorance, théorie de Dempster-Shafer, valeurs sont des intervalles, logique floue, imprécision, localité, détachement, détacher, vérifonctionnalité, règles, facteurs de certitude, théorie de Dempster-Shafer, incertitude, ignorance, fonction de croyance, masses, théorie des ensembles flous, logique floue, contrôle flou, distribution probit, ensemble aléatoires,

état de croyance, état, modèle de transition, modèle de capteur, modèles de Markov cachés, les filtres de Kalman, réseaux bayésiens dynamiques, coupes temporelles, equations différentielles stochastiques, hypothèse de Markov, processus de Markov, chaines de Markov d'ordre 1, processus stationnaire, hypothèse de Markov pour le capteur, modèle d'observation, 

Filtrage, état de croyance, estimation d'état, P(Xt), vraisemblance, Prédiction, lissage, explication la plus vraisemblable,  algorithme EM, estimation récursive, distribution stationnaire, prédiction, temps de mélange, vraisemblable, lissage, algorithme forward-backward, lissage à délai fixe, m, algorithme de Viterbi, modèle de Markov caché, MMC, localisation, filtrage de Kalman, linéaire gaussiennes, gausienne multivariée, parcours aléatoire, complétion du carrée,  matrice de gain de Kalman, filtre de Kalman étendu, non linéaire, filtre de Kalman commuté, réseau bayésien dynamique, RBD, modèle d'erreur gaussien, distribution bêta, défaillance temporaire, modèle de défaillance temporaire, modèle de défaillance persistante, arc de persistance, dépliement, éliminaton des variables, pondération par la vraisemblance, filtrage particulaire, incertitude d'identité, association des données, filtre par plus proche voisin, l'algorithme hongrois, filtrage particulaire, MCMC, fausses alertes, fautes de détection, réseaux de décision (ou diagrammes d'influence), fonction d'utilité, utilité espérée, maximum d'utilité espérée (MEU), loterie, ordonnancement, transitivité, continuité, substituabilité, monotonie, décomposabilité, principe d'utilité, principe du maximum de l'utilité espérée. fonction de valeur, fonction d'utilité ordinale, élicitation des préférences, utilités normalisées, loterie standard, micromort, QALY, préférence monotone, valeur monétaire espérée, évitement du risque, recherche du risque, équivalent certain, prime d'assurance, neutre par rapport au risque, non biasées, malédiction, théorie normative, théorie descriptive, effet de certitude, regret, évitement de l'amiguité, effet de cadrage, effet d'ancrage,  psychologie évolutionniste, théorie de l'utilité multi-attribut, dominance stricte, dominance stricte, dominance stochastique, distributions cumulées, réseaux probabilistes qualitatifs, théorèmes de représentation, indépendance préférentielle, indépendance préférentielle mutuelle, fonction de valeur additive, indépendance des utilités, mutuellement indépendant au sens de l'utilité, fonction d'utilité multiplicative, diagramme d'influence, réseau de décision, les noeuds de hasard, les noeuds de décision, noeuds d'utilité, fonction actions-utilités, Q-fonction, théorie de la valeur de l'information, état de croyance, valeur de l'information parfaite, myope, analyse de la décision, preneur de décision, analyste de la décision, la coarctation aortique, créer un modèle causal, simplifier pour obtenir un modèle de décision qualificatif,assigner  des probabilités, assigner des utilités, vérifier et raffiner le modèle, étalon-or, effectuer une analyse de sensibilité, 

Problèmes de décision séquentiels, théorie des jeux, entièrement observable, modèle de transition, markoviennes, réseau bayésien dynamique, historique de l'environnement, récompense, processus de décision de Markov, PDM, politique, politique optimale, théorie de l'utilité multiattribut, horizon infini, horizon fini, non stationnaire, stationnaire, stationnaires, récompenses additives, récompenses escomptées, facteur d'escompte, politique propre, récompense moyenne, itération de la valeur, équation de Bellman, mise à jour de Bellman, contraction, norme max, perte de politique, itération de la politique, Evaluation de la politique, amélioration de la politique, itération de la politique modifiée, itération de la politique asynchrone, entierement observable, partiellement observable, PDM partiellement observables, modèle de capteur, état de croyance, filtrage, plan conditionnel, réseau bayésien dynamique, réseaux de décision, réseau de décision dynamique, représentation factorisées, agent fondé sur l'utilité, information parfaite et information imparfaite, conception d'agents, mourre à deux doigts, conception de mécanismes, systèmes multiagents, joueurs, actions, fonction de gains, forme stratégique (ou encore forme normale). Stratégie, stratégie pure, stratégie mixte, profil stratégique, résultat, solution, dilemme, stratégie dominante, domine fortement, domine faiblement, optimal  au sens de Pareto, pareto-optimal, dominé au sens de Pareto, ou pareto-dominé, équilibre de stratégies dominantes, équilibre, optimum local, équilibre de Nash, jeu à répétition, jeux de coordination, à somme nulle, maximin, minimax, équilibre maximin, programmation linéaire, jeu répété, punition perpétuelle, tac au tac, forme extensive, mémoire parfaite, états de croyance, ensembles d'informations, forme séquentielle, abstraction, actions, stratégies, Hasard, Utiltés, équilibre de Bayes-Nash, conception de mécanismes, théorie des jeux inverse, mécanisme, évaluation privée, évaluation collective, enchère ascendante, enchère anglaise, réserve, efficace, entente, stratégie dominante, incitatif, vérace, incitation compatible, principe de révélation, vente aux enchères scellés, enchères scellés au prix enchères de Vickrey, au premier prix, théorème d'équivalence des revenus, tragédie des pré communs, externalités, mécanisme de Vickrey-Clarke-Groves, ou VCG, 

Apprend, les composants qui peuvent être le résultat d'un apprentissage, représentation et connaissances a priori, représentation factorisée, apprentissage inductif, apprentissage analytique ou déductif : les feedbacks dont on peut apprendre, l'apprentissage non supervisé, clustering, apprentissage par renforcement, apprentissage supervisé, apprentissage semi-supervisé,  ensemble d'apprentissage, hypothèse, ensemble de test, généralise, classification, régression, espace d'hypothèsess, cohérente, rasoir d'Occam, réalisable, négatif, arbre de décision, positif,
courbe d'apprentissage, entropie, surapprentissage, gain d'information, élagage des arbres de décision, signifiance statistique, hypothèse nulle, élagage, arrêt précoce, données manquantes, attributs à plusieurs valeurs, rapport de gain, attributs d'entrée à valeurs continues ou entières, attributs de sortie à valeurs continues, arbre de régression, hypothèse stationnaire, i.i.d, taux d'erreur, validation croisée hold-out, validation croisée k-uple, validation croisée leave-one-out, LOOCV, dévoilant, ensemble de validation, sélection de modèle, optimisation, emballage, fonction de perte, perte en généralisation, perte empirique, apprentissage à petite échelle, apprentissage à grande échelle, régularisation, sélection d'attributs, longueur de description minimale, MDL, théorie de l'apprentissage, probablement approximativement correcte, apprentissage PAC, taux d'erreur, approximativement, correcte, boule, compléxité d'échantillonage, 

poids, w, régression linéaire, espace des poids, convexe, gradient descente du gradient, taille du pas, taux d'apprentissage, descente du gradient en batch, descente de gradient, descente du gradient stochastique, regression linéaire à plusieurs variables, matrice de données, surapprentissage, régularisation, modèle parcimonieux, frontière de décision, séparateur linéaire, linéairement séparables, fonction de seuil, règle d'apprentissage du perceptrion, courbe d'apprentissage, régression logistique, règle de dérivation en chaîne, neuronnes, réseaux de neuronnes, connexionnismes, calcul en parrallèle distribué et calcul neuronal, neurosciences algorithmiques, unités, connexions, poids, activation, poids, fonction d'activation, perceptron, perception sigmoide, réseau feed-forward, réseau récurrent, couches, unités cachées, réseau de neuronnes à une couche, réseau perceptron, règle d'apprentissage du perceptron, régression logistique, fonction de majorité, régression non linéaire,  rétropropager, surapprentissage, validation croisée, dévoillement, dégat du cerveau, optimal, pavage, modèle paramétrique, non paramétrique, apprentissage par l'exemple,  apprentissage fondé sur la mémoire, apprentissage paresseux, consultation d'une table, consultation par les k-proches visions, distance de Minkowski, distance de Hamming, normalisation, distance de Mahalanobis, malédiction de la dimensionnalité, hachage sensible à l'emplacement,vosins approximativement les plus proches, régression par les k-proches voisins, régression pondérée localement, noyau, machines à vecteurs de support, séparateur à marge maximale, astuce du noyau, séparateur à marge maximale, marge, programmation quadratique, vecteurs du support, fonction noyau, théorème de Mercer, noyau polynomial, astuce du noyau, marge douce, noyélisée, apprentissage d'ensemble, ensemble, dopage, ensemble d'apprentissage pondérée, apprentissage faible, copie d'ensemble d'apprentissage.

Souches de décisions, apprentissage bayésien, apprentissage en ligne, algorithme aléatoire de majorité pondérée, regret, apprentissage sans regret,  NIST, 3-plus proches voisins, réseau de neuronnes à une seule couche cachée, réseaux de neurones spécialisés, réseau de neuronnes dopé, machine à vecteurs de support, machine à vecteurs de support virtuelle.

La correspondance de forme, humains, connaissances a priori, attributs, extension, faux négatif, faux postif, meilleure hypothèse courante, généralisation, spécialisation, abandon de conditions, espaces des versions, algorithme d'élimination, ensemble frontière, l'ensemble-G, l'ensemble-S, hiérarchie de généralisation, contrainte de conséquence, apprentissage par explication, EBL, pertinence, apprentissage fondé sur la pertinence, RBL, apprentissage inductif fondé sur les connaissances, KBIL, programmation logique inductive PLI, mémoisation, facteur de branchement, élague,  opérationnalité, déterminations, dépendances fonctionnelles, biais déclaratif, constructive, résolvant, résolution inverse, résolution, résolution linéaire, conséquence inverse, données, hypothèses, observations, apprentissage bayesien, probabilité a priori, vraisemblance, maximum a posteriori, surapprentissage, MDL, longueur de description minimale, uniforme, maximum de vraisemblance, estimation de densité, données complètes, apprentissage de paramètres, paramètre, log-vraisemblance, bayésien naif, gausienn linéaire, régression linéaire, hypothèse a priori, distributions bêta, hyperparamètre, conjuguée, compteurs virtuels, indépendance des paramètres, estimation de densité non paramétrique, k-plus proche voisins, fonctions noyau, variables cachées, variables latentes, espérence-maximisation, expectation-maximization, classification non supervisée, loi de mélange, composantes, mélange de gaussienne, variables indicatrices,  apprentissage, modèle bayésien naif, forward-backward, lissant, filtrant


Renforcement, récompense, processus de décision de Markov, apprentissage par renforcement, itération de la politique, modèle de transition, fonction de récompense, évaluation de politiques, essais, facteur d'escompte, estimation directe de l'utilité, contrôle adaptatif, la récompense à venir, programmation dynamique adaptative, itération de la politique modifiée, apprentissage par renforcement bayésien, théorie du contrôle  robuste, taux d'apprentissage, différence temporelle, balayage hiérarchisé,  agent glouton, exploitation, exploration, problèmes de bandits, GILE. Fonction d'exploration, Q-learning, méthode sans modèle, SARSA, algorithme basé sur une politique, basé sur une politique, approximateur de fonction, fonction d'évaluation, caractéristique (fonctions de base), apprentissage supervisé, règle de Widrow-Hoff, règle delta, recherche de politique, représentation stochastique, fonction softmax : valeur de la politique, vecteur gradient, gradient empirique, échantillonnge corrélé, pendule inversé, contrôle bang-bang, acquisition de connaissances, modèles de langage, un langage, un langage, grammaire, sémantique, ambigus, caractères, modèle n-gramme, chaine de Markov, corpus, identification de la langue, lissage, modèle backoff, lissage par interpolatin linéaire, perplexité, vocabulaire, hors-vocabulaire, classification de textes, catégorisation, détection des spams, ham, sac de mots, situation d'adversité, sélection d'attributs, compression de données, recherche d'informations, un corpus de documents, des réquêtes émises dans un langage de requêtes. Un ensemble de résultats, compression de données, recherche d'informations, Un corpus de documents, des requêtes émises, dans un langage de requetes,  un ensemble de résultats, pertinente, Une présentation de l'ensemble de résultats, modèle booléen de mots clefs, la fonction de score BM25, index, hit list, précision, rappel, correspondance de casse (case folding), lemmatisation, synonymes, métadonnées, liens, modèle du surfeur aléatoire, autorité, concentrateur, questions-réponses, système d'extraction à base d'attributs, modèle, expression régulière, extraction relationnelle, transducteurs à états finis en cascade, segmentation, mots complexes, groupes de base, expressions, complexes, fusion des structures, problème d'incertitude sur l'identité, modèle discriminant, champ conditionnel aléatoire, champ conditionnel aléatoire linéaire, lecture artificielle

faible densité des données, communication, signes, catégorie lexicale (alias partie du discours), catégories syntaxiques, structure syntaxique, grammaire hors contexte probabiliste, une grammaire, langage, symboles non terminaux, symboles terminaux, lexique, classes ouvertes, classes fermées, capacité générative, grammaires récursivement énumérables, grammaires sensibles au contexte, grammaire hors contexte (CFG), réguliers, surgénère, arbre syntaxique, l'analyse syntaxique, diagramme (chart), analyseurs par diagrammes (chart parsers), analyseurs tabulaires, l'algorithme CYK, forme normale de Chomsky, apprentissage, corpus arboré, algorithme inside-outside, prototypes, scinder, lexicalisée, PCFG lexicalisée, tête, grammaire à clauses définies, chien, noir, génération de langage, l'accord de cas, accord sujet-verbe, sémantique compositionelle, prédicat, temporalité et temps du verbe, Quantification, forme quasi logique, pragmatique, indexicaux, acte de langage, dépendances à longue distance, trace, ambiguité, l'ambiguite lexicale, l'ambiguite syntaxique, ambiguite sémantique, métonymie, métaphore, désambiguïsation, modèle de mots, modèle mental, modèle de langage, modèle acoustique, interlangue, modèle de transfert, modèle de langage, modèle de traduction, diagnostic, corpus bilingue, expressions, trouver des textes parallèles, hansard, segementer en phrases, aligner les phrases, aligner les expressions, extraire les distorsions, améliorer les estimations avec EM.
Reconnaissance de la parole, segmentation, coarticulation, homophobes, modèle acoustique, modèle de langage, modèle de canal bruité, taux d'échantillonage, facteur de quantification, phones, phonème, trames, attributs, coefficient cepstral, modèle de phone, modèle de pronociation, coarticulation


perception capteurs, capteurs actifs, modèle de capteur, modèle objet, modèle de rendu, reconnaissance, extraction de traits, reconnaissance, reconstruction, scène, pixels, sténopé, point de fuite, flou cinétique, lentille, profondeur de champ, plan focal, projection orthographique à l'échelle, l'intensité globale, réflechir, l'ombrage, réflexion diffuse, réflexion spéculaire, spécularités, source lumineuse poinctuelle distante, albédo diffus, loi en cosinus de Lambert, ombre, interréflexions, éclairage ambiant, principe de trichromacie, constance des couleurs, contours, filtre gaussien, convolution, orientation, texture, flot optique, erreur quadratique, régions, superpixels, apparence, fenêtre glissante, réduction, aspect, l'occlusion, la déformation, caractéristique HOG, le mouvement, la vision binoculaire, les points multiples, la texture, l'ombrage, le contour, les objets familiers, foyer d'expansion, disparité, ligne de référence, fixe, texels, n, plan de sol, méthode d'alignement, R, l'orientation de l'objet dans son ensemble, l'orientation de la surface de l'objet, à P. Obliquité et d'inclinaison, forme, modèle déformable, pose, modèle de structure picturale, modèle d'apparence, soustraction d'arrière-plan, la construction de modèle, la correspondance de mouvements, la reconstruction de trajectoire

Robots, effecteurs, capteurs, manipulateurs, robots mobiles, véhicules terrestres sans pilote, robot d'exploration planétaire, véhicules aériens sans pilote, véhicules sous-marins sans équipage, robot hybride, robot humanoides, capteurs passifs, capteurs actifs, équipements de télémétrie, capteur sonar, vision stéréoscopique caméra TOF, détecteurs LIDAR, capteurs tactiles, capteurs de localisation, Global Positionning System, GPS différentiel, capteurs proprioceptifs, décodeurs d'arbre, odométrie, capteurs inertiels, capteurs de force et de couple, degrés de libertés, l'état cinématique, pose, l'état dynamique, articulations rotoèdes, articulation prismatique, degrés de liberté efficaces, degrés de liberté contrôlables, non holonome, commande différentielle, commande synchrone, dynamiquement stable, statiquement stable,  moteur électrique, actionneurs pneumatiques, actionneurs hydrauliques, estimation de l'état (ou filtrage dont nous avons déjà parlé à la section), l'état de croyance, modèle de transition, modèle de mouvement, modèle du capteur, repères, localisation Monte-Carlo, linéarisent, développement en série de Taylor, filtre de Kalman, association des données, localisation et cartographie simultanées, réduction de dimension, SLAM, autosupervisé, mouvement point-à-point, compliance, espace des configurations, planification de chemin, décomposition cellulaire, squelettisation, espace de travail, contraintes de liaison, espace des configurations, cinématique, cinématique inverse, espacé occupé, espace libre, décomposition cellulaire, décomposition cellulaire exacte, hybride A*, champ de potentiel, squelettisation, squelette, diagramme de Voronoi, la carte probabiliste, Etat le plus vraisemblable,replanification en ligne, politique, fonctions de navigation, action de collecte d'informations, cabotage, contrôle robuste, planification conformante, planification de mouvement fin, mouvements prudents, mouvements de compliance, état dynamique, équations différentielles, contrôleur, contrôleur de référence, contrôleur optimaux, contrôleurs P, paramètre de gain, théorie du contrôle, stable, strictement stable, contrôleur PD, contrôleur PID, contrôle réactif, loi de contrôle, comportement émergent, recherche de politique, architecture logicielle, architectures hybrides, architecture de subsomption, automates à états finis augmentés, l'architecture à trois couches, couche réactive, couche exécutive, couche délibérative, architecture pipeline, couche d'interface de capteur,  couche de perception, couche de planification et de contrôle, couche d'interface du véhicule














#### Infrastructure pour les algorithmes d'exploration

Mots-clefs :

#### Mesure de la performance de la résolution de problème 

Mots-clefs :

### Stratégies d'exploration non informée 

#### Exploration en largeur d'abord

Mots-clefs :

#### Exploration à cout uniforme

Mots-clefs :

#### Exploration en profondeur d'abord 

Mots-clefs :

#### Exploration en profondeur limitée

Mots-clefs :

#### Exploration itérative en profondeur 

Mots-clefs :

#### Exploration bidirectionnelle

Mots-clefs :

#### Comparaison des stratégies d'exploration non informées

Mots-clefs :



### Stratégies d’exploration informée (heuristiques) 

#### Exploration gloutonne par le meilleur d'abord

Mots-clefs :

#### Exploration A*:  minimisation du coût total estimé de la solution

Mots-clefs :

#### Exploration heuristique à mémoire limité

Mots-clefs :

#### Apprendre à mieux chercher

Mots-clefs :


### Fonctions heuristiques 
 
#### Effet de l'excatitude heuristique sur la performance 

Mots-clefs :

#### Production d'heuristiques admissibles pour les problèmes relaxés

Mots-clefs :

#### Production d'heuristiques admissibles à partir de sous-problèmes: base de données de motifs

Mots-clefs :

#### Apprentissage d'heuristique à partir de l'expérience

Mots-clefs :

 
 
 ## Résumé
***
 
 
## Chapitre 4 : Au-delà de l'exploration classique 
### Algorithmes d'exploration locale et problèmes d’optimisation 

#### Exploration par escalade (hill-climbing)

Mots-clefs :

#### Exploration par recuit simulé (simulated annealing)

Mots-clefs :

#### Exploration locale en faisceau 

Mots-clefs :


#### Algorithmes génétiques

Mots-clefs :

####

Mots-clefs :
### Exploration locale d’espaces continus 

Mots-clefs :


### Exploration avec des actions non déterministes  
#### Le monde de l'aspirateur capricieux 

Mots-clefs :


#### Arbres d'exploration ET-OU

Mots-clefs :

#### Essayer sans cesse 

Mots-clefs :

### Exploration avec des observations partielles  

#### Exploration sans observation

Mots-clefs :

#### Exploration avec observation

Mots-clefs :

#### Résolution de problèmes partiellement observables

Mots-clefs :

#### Un agent pour les envrionnements partiellement observables

Mots-clefs :


### Agents d'exploration en ligne et environnements 
#### Problèmes d'exploration en ligne

Mots-clefs :

#### Agents d'exploration en ligne

Mots-clefs :

#### Exploration en ligne locale

Mots-clefs :

#### Apprentissage et exploration en ligne

Mots-clefs :


***

## Résumé
 
## Chapitre 5 : Exploration en situation d’adversité 
### Les jeux 
####

Mots-clefs :

### Décisions optimales dans les jeux
#### L'algorithme minmax

Mots-clefs :


### Décisions optimales dans le cadre des jeux multijoueurs

### Élagage alpha-bêta 
#### Ordre des coups

Mots-clefs :

### Décisions imparfaites en temps réel 
#### Fonctions d'évaluation

Mots-clefs :

#### Exploration avec arrêt (cut profil)
#### Elagage avant
#### Exploration versus consultation


### Jeux stochastiques  
#### Fonction d'evaluation pour les jeux de hasard

Mots-clefs :

### Jeux partiellement observables
#### Kriegspiel : échecs partiellement observables

Mots-clefs :

#### Jeux de cartes 
### Etat de l’art des programmes de jeu  

Mots-clefs :

### Autres méthodes  
####

Mots-clefs :


## Résumé
***

## Chapitre 6 : Problèmes à satisfaction de contraintes 
### Définition des problèmes à satisfaction de contraintes 
#### Exemple de coloration d'un plan

Mots-clefs :

#### Exemple : ordonnancement industriel 
#### Variantes du formalisme CSP


### Propagation de contraintes : inférence dans les CSP 
#### Cohérance de noeuds 

Mots-clefs :

#### Cohérance d'arc
#### Cohérance de chemins
#### K-Cohérance
#### Contraintes globales
#### Sudoku

### Exploration avec backtracking pour les CSP  
#### Ordre des variables et des valeurs
Mots-clefs :

#### Association de l'exploration et de l'inférence
#### Backtracking intelligent : l'examen en amont

### Exploration locale pour les CSP.
####
Mots-clefs :
### La structure des problèmes.

Mots-clefs :

## Résumé


***

# Connaissances, raisonnement et planification 

## Chapitre 7 : Agents logiques 
### Agents fondés sur les connaissances 
####

Mots-clefs :


### Le monde du wumpus 
####

Mots-clefs :


### Logique  


### La logique propositionnelle : une logique très simple
#### Syntaxe

Mots-clefs :

#### Sémantique
#### Une base de connaissances simple 
#### Une procédure d'inférence simple

Mots-clefs :

### Démonstration de théorèmes en logique propositionnelle

#### Inférence et preuves
#### Preuve par résolution
#### Clauses définies et clauses de Horn
#### Chainage avant et Chainage arrière

### Vérification efficace de modèles en logique propositionnelle 

#### Un algorithme de backtracking complets

#### Algorithmes d'exploration locale
#### Le paysage des problèmes SAT aléatoires


### Agents fondés sur la logique propositionnelle

#### L'état actuel du monde 
#### Un agent hybride
#### Construire des plans par inférence propositionnelle


Mots-clefs :


## Résumé
***


## Chapitre 8 : Logique du premier ordre 
### Retour sur la représentation
#### Le langage de la pensée
#### Combiner le meilleur des langages formels et naturels

Mots-clefs :

### Syntaxe et sémantique de la logique du premier ordre 
#### Modèles de la logique du premier ordre 
#### Symboles et interprétation
#### Termes
#### Enoncés atomiques
#### Enoncés complexes
#### Quantificateurs
#### Egalité 
#### Une autre sémantique

Mots-clefs :

### Utiliser la logique du premier ordre 
#### Assertions et requêtes en logique du premier ordre 
#### Nombres, ensembles et listes
#### Le monde du wumpus


Mots-clefs :


### Ingénierie des connaissances en logique du premier ordre
#### Le processus d'ingéniere des connaissances
#### Le domaine des circuits électroniques

Mots-clefs :



## Résumé

***

## Chapitre 9 : L'inférence en logique du premier ordre 
### Inférence propositionnelle us inférence du premier ordre 
#### Règles d'inférence pour les quantificateurs 

#### Réduction à l'inférence propositionnelle

Mots-clefs :


### Unification et élargissement 
#### Une règle d'inférence du premier ordre 
#### Unification
#### Stockage et récupération

Mots-clefs :


### Chaînage avant
#### Clauses définies du premier ordre 
#### Un algorithme de chaînage avant simple
#### Chainage avant efficace 

Mots-clefs :


### Chaînage arrière
#### Un algorithme de chainage arrière 
#### Programmation logique
#### Implémentation efficace des programmes logiques
#### La sémantique des bases de Prolog 
#### Programmation logique avec contraintes

Mots-clefs :


### Résolution
#### Forme normale conjonctive pour la logique du premier ordre 
#### Règle de résolution des inférences
#### Complétude de la résolution
#### Egalité 
#### Stratégie de résolution


Mots-clefs :


## Résumé
***

## Chapitre 10 :  Planification classique
### Définition de la planification classique
#### Exemple :  transport de fret aréien
#### Exemple : le problème de la roue de secours
#### Exemple : le monde des blocs

####  Complexité de la planification classique 

Mots-clefs :


### Algorithmes de planification par exploration dans un espace d'états
#### Exploration en avant (progressive) dans un espace d'états
#### Exploration en arrière (régressive) des états pertinents
#### Heuristiques pour la planification

Mots-clefs :


### Graphes de plannification
#### Graphes de plannification pour l'estimation heuristique
#### L'algorithme GraphPlan
#### Terminaison de GraphPlan

Mots-clefs :

### Autres méthodes en planification classique
#### Planification classique vue comme satisfiabilité booléene
#### La planification vue comme déduction logique du premier ordre : le calcul situationnel 
#### La planification vue comme satisfaction des contraintes 
#### La planification vue comme affinement des plans partiellement ordonnées

Mots-clefs :


### Analyse des méthodes de plannification
####

Mots-clefs :



## Résumé



## Chapitre 11 :  Planification et action dans le monde réel 

### Temps, ordonnacement et ressources
#### Représentation des contraintes de temps et de ressources
#### Resolution des problèmes d'ordonnancement
####

### Planification hiérarchique
#### Action de haut niveau 
#### Recherche de solutions primitives
#### Recherche de solutions abstraites 

### Planification et action dans des domaines non déterministes 
#### Planification sans capteurs
#### Plannification avec contingence
#### Replanification en ligne d

### Planification multiagent
#### Plannification d'actions simultanées 
#### Planification multiagent : coopération et coordination


## Résumé
***

## Chapitre 12 :  Représentation des connaissances 
### Ingénierie ontologique 
####
####
####
####

Mots-clefs :

### Catégories et objets
#### Composition physique
#### Mesures
#### Objets : matière et choses 
####

Mots-clefs :

### Evénements 



### Evénements mentaux et objets mentaux 
#### Processus
#### Intervalle de temps
#### Fluents et objets 
####

Mots-clefs :

### Systèmes de raisonnement pour les catégories 
#### Réseaux sémantiques
#### Logiques de description
####
####

Mots-clefs :

###  Raisonnements avec informations par défaut 
#### Circonscription et logique des défauts
####
####
####

Mots-clefs :



### Systèmes à maintenance de vérité 
####
####
####
####

Mots-clefs :


### Le monde du commerce électronique 
#### Suivi des liens
#### Comparaisons de offres 
####
####


Mots-clefs :


## Résumé
***

# IV Connaître et penser l’incertain 

## Chapitre 13 :  Quantification de l'incertitude 
### Agir dans l'incertitude 
#### Synthétiser l'incertitude
#### Incertitude et décisions rationnelles


Mots-clefs :

### Probabilités: notations de base
#### Ce que sont les probabilités 
#### Le langage de la théorie des probabilités 
#### Axiomes des probabilités et leur raison d'être


Mots-clefs :


### Inférence utilisant des distributions conjointes complété



Mots-clefs :


### Indépendance



Mots-clefs :


### La régle de Bayes et son utilisation
#### Application de la règle de Bayes : le cas simple
#### Application de la règle à plusieurs observations


Mots-clefs :


### Le monde du wumps revisité


Mots-clefs :



## Résumé
***

## Chapitre 14 : Raisonnement probabiliste 
### Représentation des connaissances dans un domaine incertain
####
####
####
####

Mots-clefs :


### Sémantique des réseaux bayésiens 
#### Représentation de la distribution de probabilités conjointe complète 
#### Une méthode pour construire des réseaux bayésiens 
#### Compacité et ordre des noeuds 
#### Relations d'indépendance conditionnelle dans les réseaux bayésiens


Mots-clefs :


### Représentation efficace des distributions conditionnelles  
#### Réseaux bayésiens à variables continues


Mots-clefs :


### Inférence exacte dans les réseaux bayésiens
#### Inférence par énumération
#### L'algorithme d'éliminationd des variables
#### Complexité de l'inférence exacte 
#### Algorithmes de groupement (clustering)

Mots-clefs :


### Inférence approchée dans les réseaux bayésiens
#### Méthodes d'échantillonnage direct 
#### Pondération par la vraisemblance 
#### Inférence par simulation de chaînes de Markov Monte-Carlo 
#### Pourquoi l'échantillonage de Gibbs fonctionne

Mots-clefs :


### Modèles relationnels et modèles probabilistes du premier ordre 
#### Mondes possibles 
#### modèles probabilistes relationnels
#### modèles probabilistes en univers ouvert

### Méthodes à base de règles pour le raisonnement incertain
### Représentation de l'ignorance : la théorie de Dempster-Shafer 
### Représentation de l'imprécision : ensembles flous et logique floue


## Résumé
***

## Chapitre 15 :  Raisonnement probabiliste temporel 
### Temps et incertitude 
#### Etats et observations
#### Modèles de transition et modèles de capteur

Mots-clefs :


### L'inteférence dans les modèles temporels 
#### Filtrage et prédiction
#### Lissage
#### Découverte de la séquence la plus probable


### Modèles de Markov cachés 
#### Algorithmes matriciels simplifiés 
#### Exemple d'un MCC : localisation


Mots-clefs :


### Filtres de Kalman
#### Mise à jour des distributions gaussiennes 
#### Un exemple unidimensionnel simple
#### Le cas général 
#### Applications du filtrage de Kalman

Mots-clefs :


### Réseaux bayésiens dynamiques 
#### Construction de RBD
#### Inférence exacte dans les RBD
#### Inférence approchée dans les RBD


Mots-clefs :


### Suivre de nombreux objets


Mots-clefs :



## Résumé
***

## Chapitre 16 :  Prise de décisions simples 
### Désirs, croyances et incertitude 


Mots-clefs :


### Concepts de base de la théorie de Futilité 
#### Contraintes sur les préférences rationnelles 
#### Des préférences à l'utilité
#### Evaluation de l'utilité et échelles d'utilité 
#### L'utilité de l'argent
#### Utilité espérée et déception postdécisionnelle 
#### Jugement humain et irrationalité


Mots-clefs :


### Fonctions d’utilité
#### Dominance 
#### Structure de préférences et utilité multi-attribut
#### Préférences sans incertitude 
#### Préférences avec incertitude 

### Fonctions d’utilité multiattribut 


Mots-clefs :


### Réseaux de décision 
#### Répresentation d'un problème avec un réseau de décision
#### Evalation dans les réseaux de décision
#### 
####

Mots-clefs :


### La valeur de l’information
#### Un exemple simple 
#### Information parfaite : formule générale 
#### Propriétes de la valeur de l'information
#### Implémentation d'un agent de collecte d'informations


Mots-clefs :


### Systèmes experts utilisant la théorie de la décision 
####
####
####
####

Mots-clefs :



## Résumé
 
***

## Chapitre 17 :  Prises de décisions complexes 
### Problèmes de décision séquentiels  
#### Un exemple
#### De l'utilité en fonction du temps
#### Politiques optimales et utilités des états
####

Mots-clefs :


### Itération de la valeur  
#### Equations de Bellman pour les utilités
#### L'algorithme d'itération de la valeur
#### Convergence de l'itération de la valeur 
####

Mots-clefs :


### Itération de la politique  
####
####
####
####

Mots-clefs :


### PDM partiellement observables 
#### Définition des PDMPO
#### Itération de la valeur pour les PDMPO
#### Agents en ligne pour les PDMPO
####

Mots-clefs :


### Décisions et agents multiples : la théorie des jeux 
#### Jeux à un tour 
#### Jeux répétées
#### Jeux séquentiels


Mots-clefs :


### Conception de mécanismes   
#### Enchères
#### Biens collectifs 



Mots-clefs :



## Résumé


***
# V Apprentissage 

## Chapitre 18 :  Apprendre à partir d'exemples 
### Les différentes formes d’apprentissage 
####
####
####
####

Mots-clefs :


### Apprentissage supervisé
####
####
####
####

Mots-clefs :

### Apprentissage d’arbres de décision 
#### Réprésentation par arbre de décision
#### Expressivité des arbres de décision
#### Inférer des arbres de décision à partir d'exemples
#### Choix de bons attributs à tester
#### Généralisation et surapprentissage 

#### Elargir le champ d'application des arbres de décision

Mots-clefs :


### Évaluation et choix de la meilleure hypothèse
#### Choix du modèle : Complexité contre précision de l'approximation
#### Du taux d'erreur à la perte
#### Régularisation
####

Mots-clefs :

### Théorie de l'apprentissage
#### Exemple d'apprentissage PAC : apprentissage de listes de décision
#### Régression linéaire à une variable
#### Régression linéaire à plusieurs variables 
#### Classificateurs linéaires à seuil dur

Mots-clefs :

### Régression et classification avec des modèles linéaires
#### Classification linéaire avec régression logistique 
#### Structure des réseaux de neuronnes 
#### Réseaux neuronaux à une seule couche (percepton)
#### Réseaux de neurones feed-forward à plusieurs couches 

Mots-clefs :



### Réseaux de neurones artificiels
#### Apprentissage dans les réseaux à plusieurs couches
#### Apprentissage de structures de réseaux de neuronnes 
#### Modèle des plus proches voisins
#### Recherche des plus proches voisins dans les arbres k-d
#### Hachage sensible à l'emplacement 
#### Regression non paramétrique


Mots-clefs :


### Modèles non paramétriques
####
####
####
####

Mots-clefs :

### Machines à vecteurs de support 
####
####
####
####

Mots-clefs :


### Méthodes d’ensemble en apprentissage
#### Apprentissage en ligne
####
####
####

Mots-clefs :



### L'apprentissage artificiel en pratique
#### Etude de cas : reconnaissance des chiffres manuscrits
#### Etude de cas : Sens des mots et prix des maisons
####
####


Mots-clefs :


## Résumé

***

## Chapitre 19 : Connaissances et apprentissage 
### Une formulation logique de l'apprentissage 
#### Exemple et hypothèses 
#### Meilleures hypothèse courante
#### Moindre engagement
####

Mots-clefs :


### Connaissances et apprentissage 
#### Quelques exemples simples
#### Quelques schémas généraux 
####
####

Mots-clefs :

### Apprentissage par explication
#### Extraction de règles générales à partir d'exemples
#### Amélioration de l'efficacité
#### Détermination de l'espace des hypothèses 
#### Apprentissage et utilisation des informations sur la pertinence 

Mots-clefs :



### Apprentissage fonde sur la pertinence
#### Un exemple 
#### Méthodes d'apprentissage inductif descendants 
#### Apprentissage inductif par résolution inverse
#### Découvertes par programmation logique inductive 

Mots-clefs :

### Programmation logique inductive
####
####
####
####


Mots-clefs :




## Résumé

***


## Chapitre 20 : Apprentissage de modèles probabilistes 
### L’apprentissage statistique
####
####
####
####

Mots-clefs :

### Apprentissage avec données complètes
#### Apprentissage de paramètres par maximum de vraisemblance : les modèles discrets
#### Modèles bayésins naifs 
#### Apprentissage de paramètres par maximum de vraisemblance : les modèles continus
#### Apprentissage bayésien de paramètres 

Mots-clefs :



### Apprentissage avec variables cachées : l'algorithme LM 
#### Apprentissage de la structure des réseaux bayésiens
#### Estimation de densité avec des modèles non paramétriques
#### Classification non supervisée : Apprentissage de mélanges de gaussiennes
#### Apprentissage de réseaux bayésiens avec variables cachées


Mots-clefs :

## Résumé

***

## Chapitre 21 : Apprentissage par renforcement 
### Introduction
#### Apprentissage de modèles de Markov cachés 
#### Forme générale de l'algorithme EM
#### Apprentissage de structures de réseaux bayésiens avec variables cachés
#### 

Mots-clefs :


### Apprentissage par renforcement passif
#### Estimation directe de l'utilité
#### Programmation dynamique adaptative 
#### Apprentissage par différence temporelle
#### Exploration 
#### Apprentissage d'une fonction action-valeur

Mots-clefs :

### Apprentissage par renforcement actif 
#### Application aux jeux 
#### Applications au contrôle de robots
####
####

Mots-clefs :

### Généralisation et apprentissage par renforcement
#### Modèles de caractères n-grammes 
#### Lissage des modèles n-grammes 
#### Evaluation des modèles
#### Modèles de mots n-grammes 

Mots-clefs :


### Recherche de politique




Mots-clefs :


### Applications de l’apprentissage par renforcement



































Mots-clefs :



## Résumé


***

# VI Communication, perception et action 

## Chapitre 22 : Traitement du langage naturel 
### Modèles de langage
####
####
####
####

Mots-clefs :


### Classification de textes
####
####
####
#### Classification par compression de données 

Mots-clefs :


### Recherche d’informations
#### Fonctions de calcul de score en recherche d'informations
#### Evaluation des systèmes de recherche d'informations
#### Affinements de la recherche d'informations
#### L'algorithme PageRank
#### L'algorithme HITS 
#### Systèmes de questions-réponses 

Mots-clefs :


### Extraction d'informations
#### Automates à états finis pour l'extraction d'informations
#### Modèles probabilistes pour l'extraction d'informations
#### Champs conditionnels aléatoires pour l'extraction d'informations
#### Extraction d'ontologies à partir de grands corpus 
#### Construction automatique de modèles
#### Lecture artificielle

Mots-clefs :



## Résumé
***
 
 
## Chapitre 23 :  Langage naturel et communication 
### Grammaires à structure de phrase 
#### Le lexique de E0
#### La grammaire de E0


Mots-clefs :

### Analyse syntaxique {pars in g
#### Apprentissage de probabilités pour les PCFG
#### Comparaison des modèles hors contexte et de Markov 


Mots-clefs :



### Grammaires augmentées et interprétation sémantique 
#### PCFG lexicalisées
#### Définition formelle  des règles de grammaire augmentées
#### Accord de cas et accord sujet-verbe
#### Interprétation sémantique 
#### Complications


Mots-clefs :

### Traduction automatique
#### Systèmes  de traduction automatique
#### Traduction automatique 


Mots-clefs :


### Reconnaissance de la parole

#### Le modèle acoustique 
#### Modèle de langage 
#### Construction d'un système de reconnaissance de la parole

Mots-clefs :



## Résumé
 
***

##  Chapitre 24 : 

### Formation des images
#### Images sans lentille : le sténopé 
#### Système de lentilles 
#### La projection orthographique à l'échelle.
#### Lumière et ombrage 
#### Couleur 

### Les premières opérations de traitement d'image
#### La détection de contours 
#### La texture 
#### Le flot optique
####  La segmentation d'image

Mots-clefs :


###  La reconnaissance d'objet en fonction de l’apparence
#### Aspects complexes et élements de motifs
#### La détection de piétons grâce aux caractéristiques HOG



Mots-clefs :

###  Reconstruire le monde en 3D
#### La parallaxe de mouvement
#### La vision binoculaire
#### Les points de vue multiples
#### Texture
#### Contour
#### Les objets et la structure géométrique des scènes


Mots-clefs :

###  La reconnaissance d'objets à partir d'une information structurelle
#### La géométrie des corps : détecter les bras et les jambes 
#### L'apparence cohérente : suivre des individus dans une vidéo
####
####

Mots-clefs :




## Résumé

***
 
## Chapitre 25 : Robotique 


### Utiliser la vision
#### Les mots et les images 
#### Reconstruction à partir de vues multiples 
#### Utiliser la vision pour contrôler le mouvement 
#### Aspects matériels 
####

Mots-clefs :


### Aspects matériels
##### Capteurs 
##### Effecteurs 

Mots-clefs :


### Perception robotique
#### Localisation et cartographie
#### Autres types de perception 
#### L'apprentissage artificiel en perception robotique


Mots-clefs :


### Planification du mouvement
#### Espaces des configurations
#### Méthodes de décomposition cellulaire 
#### Fonctions de coût modifiés 
#### Méthode de squelettisation

Mots-clefs :

### Planification de mouvements incertains 
#### Méthodes robustes
####
####
####

Mots-clefs :



### Le mouvement
#### Dynamique et contrôle 
#### Contrôle de champ de potentiel 
#### Contrôle réactif 


Mots-clefs :


### Contrôle d'apprentissage par renforcement . .

Mots-clefs :


### Architectures logicielles en robotique
#### L'architecture de subsomption
#### L'architecture à trois couches
#### L'architecture pipeline


Mots-clefs :

### Domaines d'application


Mots-clefs :

## Résumé

***

## Chapitre 26
### IA forte: les machines peuvent-elles réeLlement penser
#### L'argument de l'incapacité
#### L'objection mathématique
#### L'argument de l'informalité 
Mots-clefs :

### Éthique et risques du développement de l'intelligence artificielle
#### Le fonctionnalisme et l'expérience du cerveau dans la cuve
#### Le fonctionnalisme et l'expérience du cerveau remplacé
#### Le naturalisme biologique et la chambre chinoise
#### La conscience, les qualia et le fossé explicatif
Mots-clefs :


## Résumé

***
## Chapitre 27 : IA : le présent et le futur 
### Les composants des agents. 
####
####
####
####

Mots-clefs :
### Architectures de l’agent 
####
####
####
####
Mots-clefs :

### Sommes-nous sur la bonne voie ? 
####
####
####
####

Mots-clefs :
### Et si l'IA atteignait son but ? 
####
####
####
####

Mots-clefs :

## Résumé



 ## Chapitre 1 :
 #### Résumé
 
  Ce chapitre a défini l’IA et tracé l’arrière-plan historique et culturel de son développement : 
 - L’IA peut être envisagée avec différents objectifs en tête. Les deux questions essentielles qu’il convient de se poser sont celles-ci: vous intéressez-vous plutôt à la pensée ou au comportement? Voulez-vous prendre modèle sur les humains ou travailler à partir d’une norme idéale ? 
 - Dans ce livre, nous adoptons le point de vue selon lequel l’intelligence a principalement trait à l'action rationnelle. Dans l’idéal, un agent intelligent exécute la meilleure action compte tenu de la situation. C’est dans cette perspective que nous étudions le problème de la construction d’agents intelligents.
 - Les philosophes dès l’an 400 av. J.-C.) ont rendu l’IA concevable en supposant que l'esprit peut être considéré à certains égards comme une machine, qu’il opère sur des  connaissances encodées dans un langage interne et que la pensée peut permettre de choisir les acfions à entreprendre. 
 - Les mathématiciens ont fourni les outils nécessaires à la manipulation d’énoncés logiques ou probabilistes (selon leur degré de certitude). Ils ont également défini les bases du raisonnement algorithmique
 - Les économistes ont formalisé le problème de la prise de décisions qui maximisent les gains prévisibles pour le décideur.
- Les neurobiologistes ont fait certaines découvertes sur le fonctionneme similitudes et ses différences avec un ordinateur 
- Les psychologues ont adopté l’idée selon laquelle les humains et les animaux peuvent vus comme des machines de traitement de l’information. Les linguistes ont montré que l'usage du langage s’insère dans ce modèle 
- Les informaticiens ont fourni les machines de plus en plus puissantes qui rendent possibles les applications de LIA. 
- La théorie du contrôle traite de la conception de dispositifs opérant de manière optimale à partir du feed-back fourni par l’environnement. À l’origine, les outils mathématiques utilisés par cette discipline étaient différents de ceux de l’IA, mais ces deux domaines sont en train de se rapprocher l’un de l’autre. 
- L’histoire de l'IA se caractérise par des phases de succès et d’optimisme démesuré, d'une part, et des périodes de pessimisme et de restrictions budgétaires, d’autre part. On remarque aussi des cycles d’introduction de nouvelles approches et de redéfinition systématique des meilleures d'entre elles. 
- Les avancées de l'IA se sont accélérées au cours de la dernière décennie du fait d'un plus grand usage de la méthode scientifique dans l'expérimentation et de la comparaison des approches 
- Les progrès récemment accomplos dans la compréhension des bases théoriques de l'intelligence sont allés de pair avec des améliorations des capacités des systèmes réels. Les sous domaines de l'IA ont été mieux intégrés et l'IA a trouvé un terrain commun avec d'autres disciplines
 
 ## Chapitre 2 :
 
 #### Résumé
 
  
 Ce chapitre a constitué en quelque sorte une visite éclair de FIA considérée comme la science de la conception d’agents : -  Un agent est une entité qui perçoit et agit dans un environnement. Sa fonction agent spécifie l’action qu’il exécute en réponse à une séquence de percepts donnée. 
 -  La mesure de performance évalue le comportement de l’agent dans un environnement. Un agent rationnel agit pour maximiser la valeur espérée de la mesure de la performance étant donné la séquence de percepts observée jusque-là. 
 -  La spécification d’un environnement de tâche comprend la mesure de performance, l’environnement externe, les effecteurs et les capteurs. Lorsqu’on conçoit un agent, la première étape doit toujours consister à spécifier l’environnement de tâche aussi complètement que possible. 
 -  Les environnements de tâches varient selon plusieurs dimensions significatives. Ils peuvent être entièrement ou partiellement observables, mono ou multiagents, déterministes ou stochastiques, épisodiques ou séquentiels, statiques ou dynamiques, discrets ou continus, et connus ou inconnus. 
 -  Le programme agent implémente la fonction agent. Il existe différentes conceptions de programmes agents de base qui reflètent le type d’informations rendues explicites et utilisées dans le processus de décision. Ces conceptions sont plus ou moins efficaces, plus ou moins compactes et plus ou moins souples. La conception appropriée dépend de la nature de l’environnement. 
 -  Les agents réflexes simples répondent directement aux percepts, tandis que les agents réflexes fondés sur des modèles maintiennent un état interne afin de suivre l’évolution des aspects du monde non discernables dans le percept courant. Les agents fondés sur des buts agissent pour atteindre des objectifs tandis que les agents fondés sur Futilité essaient de maximiser leur « satisfaction » espérée. 
 -  Tous les agents peuvent améliorer leur performance grâce à l’apprentissage.

 ## Chapitre 3 :
 
 #### Résumé
 
 Ce chapitre a présenté les méthodes auxquelles un agent peut recourir pour choisir des actions dansées environnements déterministes, observables, statiques et entièrement connus. 
 En pareil cas, l’agent peut construire des séquences d’actions qui atteignent ses buts; ce processus s’appelle exploration.
 Afin qu'un agent puisse commencer à explorer pour trouver des solutions, il faut d’abord identifier le but et formuler précisément le problème. 
 -  Un problème se compose de cinq parties: l’état initial, un ensemble d’actions, un modèle de transition décrivant les résultats de ces actions, une fonction de test de but et une lonction de coût de chemin. L’environnement du problème est représenté par un espace des états. Un chemin dans l’espace des états allant de l’état initial à un état but est une solution. 
 -  Les algorithmes d exploration traitent les états et les actions comme étant atomiques : ils ne tiennent pas compte de leur éventuelle structure interne. -  Un algorithme général d’exploration dans un arbre tel que EXPLORATION-ARBRE considère tous les chemins possibles pour trouver une solution, tandis qu'un algorithme d’exploration dans un graphe tel que Exploration-Graphe ignore les chemins redondants. 
 -   Les algorithmes d’exploration sont évalués selon leur complétude, leur optimalité, leur complexité en temps et leur complexité en espace. La complexité dépend de fi, le facteur de branchement dans l’espace des états, et de d, la profondeur de la solution la moins profonde.   
 -   Les méthodes d’exploration non informée ont accès seulement à la définition de problème. Les algorithmes de base sont les suivants: -  L’exploration en largeur développe les nœuds les moins profonds d’abord ; elle est complète, optimale pour des coûts d'étape unitaires, mais de complexité en espace exponentielle. 
 -   L'exploration à coût uniforme développe le nœud ayant le plus bas coût de chemin, gin), et est optimale pour des coûts d’étape quelconques. 
 -   L’exploration en profondeur d’abord développe le nœud non développé le plus profond d’abord. Elle n’est ni complète ni optimale, mais possède une complexité en espace linéaire. L exploration limitée en profondeur ajoute une limite de profondeur. 
 -   L'exploration en profondeur itérative appelle l’exploration en profondeur d’abord et augmente les limites de profondeur jusqu’à ce qu’un but soit trouvé. Elle est com­ plète, optimale pour des coûts d’étape unitaires, possède une complexité en temps comparable à celle de l’exploration en largeur, et possède une complexité en espace linéaire. 
 -  L’exploration bidirectionnelle peut énormément réduire la complexité en temps, mais elle n’est pas toujours applicable et peut exiger trop d’espace. 
 -  Les méthodes d’exploration informée peuvent avoir accès à une fonction heuristique h(n) qui estime le coût d’une solution à partir de n. 
 -  L’algorithme générique d’exploration par le meilleur d'abord choisit un nœud à développer selon une fonction d'évaluation. 
 -  L’exploration gloutonne par le meilleur d'abord développe les nœuds ayant le h(n) minimal. Elle n’est pas optimale mais est souvent efficace.
 -  L’exploration A* développe les nœuds ayant la valeur fin) = g(n) + h(n) minimale. A' est complet et optimal, à condition que h soit admissible (pour Exploration-Arbre) ou consistante (pour Exploration-Graphe). La complexité en espace d’A~ est encore prohibitive. 
 - RBFS (exploration récursive par le meilleur d'abord) et SMA* (A* sous contrainte de mémoire simplifié) sont des algorithmes d'exploration robustes et optimaux qui utilisent des quantités limitées de mémoire. S'ils disposent d'assez de temps, ils peuvent résoudre des problèmes qu'A* ne peut pas résoudre parce qu'il mangque de mémoire
 - La performance d'un alogrithme d'exploration heuristique dépend de la qualité de la fonction heuristique. On peut parfois construire de bonnes heuristiques en relaxant la définition du problème, en stockant des coûts de solutions précalculés pour des sous-problèmes dans une base de données de motifs ou en apprenant par expérience sur la classe de problème.


 ## Chapitre 4 :
 #### Résumé
 
  Ce chapitre a étudié les algorithmes d’exploration destinés aux problèmes au-delà du cas "classique" où l’on cherchait le plus court chemin vers un but dans un environnement observable, déterministe et discret :
 - Les méthodes d exploration locale comme l’escalade opèrent sur des formulations d’états complets, en ne mémorisant qu un petit nombre de nœuds. Plusieurs algorithmes stochastiques ont été développés, dont le recuit simulé, qui retourne des soin tiens optimales lorsqu’il dispose du schéma de « refroidissement » approprié.
 - De nombreuses méthodes d’exploration locale sont aussi applicables pour résoudre des problèmes  dans  des  espaces  continus.  La  programmation  linéaire  et  l'optimisation convexe traitent les problèmes obéissant à certaines restrictions sur la forme de l'espace d’états et sur la nature de la fonction objectif, et se prêtent à des algorithmes à complexité polynomiale qui sont souvent très efficaces en pratique. 
 - Un  algorithme  génétique  exécute  une  exploration  par  escalade  stochastique  dans  laquelle  on  maintient  une  large  population  d’états. Les  nouveaux  états  sont  générés  par mutation  et  par  recombinaison,  qui  combine  des  paires  d’états  issus  de  la  population. 
 - Dans  les  environnements  non  déterministes,  les  agents  peuvent  appliquer  l'exploration ET-OU  pour  produire  des  plans  contingents  qui  atteignent  le  but  indépendamment  des résultats intermédiaires obtenus pendant l'exécution. 
 - Quand   l’environnement   est   partiellement   observable,   l   étal   de   croyance   représente l’ensemble des états possibles dans lesquels l’agent peut se trouver. 
 - Des algorithmes d’exploration standard peuvent être appliqués directement à l’espace des états de croyance pour résoudre les problèmes sans capteurs, et l'exploration ET-OU des états de croyance peut résoudre des problèmes partiellement observables d’ordre général. Les algorithmes incrémentaux qui construisent état par état des solutions dans un étal de croyance sont souvent plus efficaces. 
 - Les problèmes de découverte se présentent quand l’agent ne sait rien des états et des actions  de  son  environnement.  Pour  les  environnements  explorables  sans  risque,  les agents d’exploration en ligne sont capables de construire une carte et de trouver un but s'il en existe un. La mise à jour des estimations heuristiques en fonction de l’expérience est un moyen efficace d'échapper aux minirna locaux.
 
 ## Chapitre 5 :
 
 #### Résumé
 
 Nous nous sommes intéressés à une diversité de jeux pour comprendre ce que signifie jouer de manière optimale et comment bien jouer dans la pratique : 
 -  On peut définir un jeu par l’état initial (la configuration du plateau de jeu), les actions légales à chaque état, le résultat de chaque action, un test terminal (qui indique quand le jeu est terminé) et une fonction d’utilité qui s'applique aux états terminaux.
 -  Dans les jeux à deux joueurs et à somme nulle en situation d’information parfaite, l'algorithme minimax peut sélectionner les coups optimaux en utilisant une énumération en profondeur de l’arbre de jeu. 
 -  L’algorithme d’exploration alpha-bêta calcule le même coup optimal que minimax, mais parvient à une efficacité accrue en éliminant des sous-arbres dont on prouve qu’ils n’ont pas d’influence sur le résultat. 
 -  En général, il n’est par envisageable d’examiner la totalité d’un arbre de jeu (même avec alpha-bêta). Il faut donc arrêter l' exploration à un moment donné et appliquer une fonction d’évaluation heuristique qui estime l’utilité d’un état. 
 -  Beaucoup de programmes de jeux gèrent les début et fins de partie à l’aide de tables de coups précalculées pour leur éviter d’avoir recours à une exploration 
 -  Les jeux de hasard peuvent être gérés par une extension de l'algorithme minimax qui évalue un nœud de hasard en prenant la moyenne des utilités de tous ses fils nondéréespar la probabilité de chaque fils. 
 -  Jouer de manière optimale dans des jeux à information imparfaite, tels que le kriegspiel exige de raisonner sur les états de croyance actuels et futurs de chaque joueur. On petu obtenir une approximation simple en faisant la moyenne de la valeur d'une action sur chaque configuration possible des informations manquantes
 -  Il existe des programmes capables de battre les humains à des jeux comme les échecs. Othello et le backgammon (jacquet). Les humains restent les meilleurs dans divers jeux à information imparfaite, comme le poker, le bridget le kriegspiel, et dans des jeux ayant un facteur de branchement très important et pour lesquels on dispose de très peu de savoir heuristique, comme le Go.
 
 ## Chapitre 6 :
 
 #### Résumé
 
- Les problèmes à satisfaction de contraintes (ou CSP, Constraint Satisfaction Problems) représentent un état par un ensemble de couples variable-valeur et représentent les conditions d'une solution par un ensemble de contraintes sur les variables. De nombreux problèmes du monde réel peuvent être décrits sous forme de CSP. On peut représenter la structure d’un CSP par son graphe des contraintes 
- Diverses techniques d’inférence utilisent les contraintes pour inférer quels sont couples variable-valeur cohérents quant aux contraintes imposées. Parmi ces technique figurent la cohérence de nœud, la cohérence d arc, la cohérence de chemin et cohérence. 
- L’exploration avec backtracking, qui est une tonne d’exploration en profondeur d’abord (DFS), est souvent employée pour résoudre des CSP. L’inférence peut être couplé à l'exploration 
- Les heuristiques MRV (Minimum Remaining Values) et des degrés sont des méthodes dans le cadre d’une exploration avec backtracking. L’heuristique de la valeur la moins contraignante aide à décider quelle valeur essayer d’abord pour une variable donnée.
- Le backtracking internent lorsqu’il est impossible d’assigner une valeur légale à une variable. Le backjumping orienté conflit permet de remonter directement à la source du problème. 
- L’exploration à l’aide de l’heuristique min-conflits a aussi été appliquée avec beaucoup de succès aux CSP. 
- La complexité de la résolution d’un CSP dépend beaucoup de la structure de son graphe des contraintes. Des problèmes à structure arborescente peuvent être résolus en temps linéaire. Le conditionnement du coupe-cycle peut réduire un CSP général à un problème structuré en arbre. Il est très efficace si l’on peut trouver un petit ensemble « coupe- cycle ». Les techniques de décomposition en arbre transforment le CSP en arbre de sous-problèmes : elles sont efficaces si la largeur d'arbre du graphe des contraintes est faible.
 
 ## Chapitre 7 :
 
 #### Résumé
 
 Nous avons présenté les agents fondés sur les connaissances, et montré comment définir une logique qui permette à de tels agents de raisonner sur le monde. Voici les principaux points : 
 -  Les agents intelligents ont besoin de connaissances sur le monde, afin de parvenir à prendre de bonnes décisions. 
 -  Les connaissances sont contenues dans les agents sous la forme d énoncés formulés dans un langage de représentations des connaissances et stockés dans une base de connaissances. 
 -  Un agent fondé sur les connaissances se compose d’une base de connaissances et d’un mécanisme d’inférence. Il opère en stockant dans la base des énoncés relatifs au monde, applique le mécanisme d'inférence pour inférer de nouveaux énoncés, derniers pour décider de l'action à entreprendre. 
 -  Un langage de représentation est défini par sa syntaxe, qui spécifié la structure des énoncés, et par sa sémantique,qui définit la vérité de chaque énoncé dans chaque monde possible ou modèle. 
 -  La relation de conséquence entre les énoncés est capitale pour comprendre le raison nement. Un énoncé a a pour conséquence un autre énoncé B si B est vrai dans tous les mondes où a est vrai. La validité de l’énoncé a => B et l’insatisfiabilité de l'énoncé a^¬B sont des définitions équivalentes
 -  L’inférence est le processus consistant à dériver de nouveaux énoncés à partir des anciens. Les algorithmes d’inférence valides ne dérivent que les énoncés qui sont des conséquences. Les algorithmes complets dérivent tous les énoncés qui sont des conséquences. 
 -  La  logique  propositionnelle  est  un  langage  simple  constitué  de  symboles  propositionnels  et  de  connecteurs  logiques.  Elle  peut  traiter  des  propositions  qui  sont  connues pour être vraies, connues pour être fausses ou complètement inconnues. 
 -  L’ensemble  des  modèles  possibles,  étant  donné  un  vocabulaire  de  propositions  simple, est  fini,  si  bien  que  l'on  peut  vérifier  la  relation  de  conséquence  en  énumérant  les modèles.  Les  algorithmes  d’inférence  par  vérification  de  modèles  pour  la  logique  propositionnelle  comprennent  les  méthodes  parbacktracking  et  par  exploration  locale.  Ils peuvent  souvent  résoudre  très  rapidement  des  problèmes  de  grande  taille 
 -  Les  règles  d’inférence  sont  des  motifs  d’inférence  valide  qui  peuvent  servir  à  trouver des preuves. La règle de résolution aboutit à un algorithme d'inférence complet pour les bases  de  connaissances  exprimées  en  forme  normale  conjonctive.  Le  chaînage  avant et le chaînage arrière sont des algorithmes de raisonnement très naturels pour les bases de connaissances en forme de Horn.
 -  Des méthodes d’exploration locale comme WalkSAT peuvent servir à trouver des solutions. Les algorithmes de ce type sont valides mais ne sont pas complets
 -  L’estimation logique des états consiste à maintenir un énoncé logique qui décrit l’en semble des états possibles cohérents avec l’historique des observations. Chaque étape de la mise à jour nécessite une inférence logique qui utilise le modèle de transition de l'environnement, lequel est construit à partir des axiomes de l'état successeur qui spécifient comment chaque fluent change.
 -  Dans un agent logique, les décisions peuvent être prises à l'aide d'un solveur SAT, qui trouve les modèles possibles en spécifiant les séquences d'actions futures qui atteignent le but. Cette approche ne fonctionne que dans des environnements entièrement observables ou dépourvus de capteurs. 
 -  La logique propositionnelle s'adapte mal aux environnements de taille illimitée, parce qu'il lui manque la puissance qui lui permettrait de traiter de manière concise le temps, l'espace et les schémas universels des relations entre objets.
 -  de la mise à jour nécessite une mterence logique qui utilise le modèle environnement, lequel est construit a partir des axiomes :ifient comment chaaue fluent change. 
 
 ## Chapitre 8 :
 

 
 #### Résumé
 
  Ce chapitre a présenté la logique du premier ordre, un langage de représentation beau coup plus puissant que la logique propositionnelle. Plusieurs points sont importants: 
 - Les langages de représentation des connaissances doivent être declaratits. composition nels, expressifs, indépendants du contexte et dépourvus d’ambiguïté. 
 - Les logiques diffèrent quant à leurs positions ontologiques et épistémologiques. Alors que la logique propositionnelle ne suppose que l’existence de laits, la logique du pre mier ordre suppose l’existence d’objets et de relations, ce qui lui permet de gagner en puissance expressive. 
 - La syntaxe de la logique du premier ordre s’appuie sur celle de la logique propositionnelle. Elle ajoute des termes pour représenter les objets, et possède des quantificateurs universels et existentiels pour construire des assertions sur tout ou partie des valeurs possibles des variables quantifiées. 
 - En logique du premier ordre, un monde possible, ou modèle, comprend un ensemble d’objets et une interprétation qui fait correspondre des symboles de constantes aux objets, des symboles de prédicats aux relations entre les objets et des symboles de fonctions aux fonctions sur les objets. 
 - Un énoncé atomique n’est vrai que lorsque la relation nommée par le prédicat est effective entre les objets nommés par les termes. Les interprétations étendues, qui lont correspondre des variables de quantification aux objets du modèle, définissent la vérité des énoncés quantifiés. 
 - Le développement d’une base de connaissances en logique du premier ordre exige un processus minutieux d'analyse du domaine, de choix d’un vocabulaire et d’encodage des axiomes nécessaires à la prise en charge des inférences souhaitées.

 ## Chapitre 9 :
 
 #### Résumé
 
 Nous avons présenté une analyse de l'inférence en logique du premier ordre, ainsi que plusieurs algorithmes pour la réaliser :
 - Une première approche utiliser les règles d'inférence (Instanciation universelle ou  instanciation existentielle) pour propositionnaliser le problème d'inférence. Elle est généralement très lente, à moins que le domaine ne soit petit.
 - Le  recours  à  l’unification  pour  identifier  les  substitutions  de  variables  appropriées élimine  l’étape  d'instanciation  dans  les  preuves  du  premier  ordre,  ce  qui  améliore l'efficacité du processus dans de nombreux cas. 
 - Une version élargie du modus ponens utilise l'unification pour fournir une règle d’inférence naturelle et puissante, le modus ponens généralisé. Les algorithmes de chaînage avant et de chaînage arrière appliquent cette règle à des ensembles de clauses définies. 
 - Le modus ponens est complet pour les clauses définies, bien que le problème de la conséquence logique soit semi-décidable. Pour les bases de données Datalog composés de clauses définies sans symboles de fonctions, la conséquence logique est décidable. 
 - Le chaînage avant est utilisé dans les bases de données déductives, où il peut être combiné avec les opérations de bases de données relationnelles. Il est également utilisé dans les systèmes de production qui réalisent des mises à jour efficaces avec des ensembles de règles très importants. Il est complet pour les bases de données Datalog et s’exécute en un temps polynomial. 
 - Le chaînage arrière est utilisé dans les systèmes de programmation logique, qui emploient une technologie de compilation sophistiquée pour calculer très rapidement des inférences. Il est affecté par des inférences redondantes et des boucles infinies, que la mémoïsation permet d’atténuer. 
 - Contrairement à la logique du premier ordre, Prolog utilise un monde clos avec l'hypothèse d’unicité des noms et la négation par l’échec. Cela en fait un langage de programmation pratique, mais l’éloigne de la logique pure. 
 - La règle générale d’inférence par résolution fournit un système de preuve complet pour la logique du premier ordre, avec des bases de connaissances en forme normale conjonctive. 
 - Il existe plusieurs stratégies pour réduire l’espace de recherche d’un système de résolution sans compromettre la complétude. L’un des problèmes les plus importants est le traitement de l’égalité, et nous avons montré comment utiliser la démodulation et la paramodulation.
 - Des démonstrateurs de théorèmes efficaces fondés sur la résolution ont été utilisées pour démontrer des théorèmes mathématiques intéressants et pour vérifier et synthétiser des matériels et des logiciels
 
 ## Chapitre 10 :
 
 #### Résumé
 
 Au fil de ce chapitre, nous avons défini le problème de la planification dans des environnements déterministes, statiques et totalement observables. Nous avons décrit la représentation PDDL utilisée pour les problèmes de planification, ainsi que plusieurs méthodes algorithmiques pour les résoudre. Les points à retenir sont : 
 -  Les systèmes de planification sont des algorithmes de résolution de problèmes qui opèrent sur des représentations explicites propositionnelles ou relationnelles d’états et d’actions. Ces représentations permettent de dériver des heuristiques efficaces et de développer des algorithmes puissants et souples pour la résolution de problèmes. 
 -  PDDL, le langage de définition de domaine de planification, permet de décrire l’état initial et l’état but sous forme de conjonctions de littéraux et les actions en termes de leurs préconditions et de leurs effets. 
 -  L’exploration dans un espace d’états peut fonctionner en avant (progression) ou en arrière (régression). Il est possible de dériver des heuristiques efficaces à partir de l’hypothèse d’indépendance des sous-buts, ainsi que de la relaxation de diverses contraintes du problème de planification. 
 -  Un graphe de planification peut être construit de manière incrémentale, en partant de l’état initial. Chaque couche contient un sur-ensemble de tous les littéraux ou actions pouvant se produire à un instant donné. Chaque couche encode aussi les relations d’exclusion mutuelle, ou mutex, entre les littéraux et les actions qui ne peuvent pas se produire simultanément. Les graphes de planification produisent des heuristiques très utiles aux planificateurs en espace d’états et en ordre partiel. Ils peuvent également être utilisés directement dans l’algorithme Graphplan. 
 -  Les autres méthodes comprennent la déduction en premier ordre sur le calcul situationnel ; l’encodage du problème de planification comme un problème de satisfiabilité ou un CSP et l’exploration explicite de l’ensemble des plans partiellement ordonnés. 
 -  Chacune des grandes approches de la planification a ses partisans, sans qu’il y ait encore de consensus sur celle qu’on peut tenir pour la meilleure. La compétition et le croisement entre elles ont permis d’augmenter significativement l’efficacité des systèmes de planification.
 
 ## Chapitre 11 :
 
 #### Résumé
 
 Ce chapitie nous a permis de traiter certains aspects complexes de la planification et de l'action dans le monde réel. En voici les principaux points : 
 - De nombreuses actions consomment des ressources, telles que de l'argent, du pétrole ou des matières premières. Il est plus pratique de traiter ces ressources sous forme de mesures numériques d’une réserve de ressources, plutôt que de raisonner sur chaque pièce de monnaie ou chaque billet dans le monde. Les actions peuvent générer et consommer des ressources. Il est généralement moins coûteux et plus efficace de vérifier si les plans partiels peuvent satisfaire aux contraintes de ressources avant d'appliquer de nouveaux affinements. 
 - Le temps est l’une des ressources les plus importantes, et des algorithmes d’ordonnancement spécialisés peuvent la traiter. On peut également combiner l’ordonnancement et la planification. 
 - La planification avec réseau hiérarchisé de tâches (HTN) permet à l’agent de prendre conseil auprès du concepteur du domaine sous la forme d actions de haut niveau (HLA) qui peuvent être implémentées de diiféientes manières par des séquences d’actions de plus bas niveau. On peut définit les effets des HLA au moyen de la sémantique angélique, ce qui permet de dériver des plans dont on peut piouver qu ils sont corrects sans se préoccuper des implémentations de bas niveau. Les méthodes avec HTN peuvent créer les très grands plans nécessaires à de nombreuses applications du monde réel. 
 - Les algorithmes de planification standard supposent des infoi mations complètes et correctes, ainsi que des environnements déterministes et totalement observables. Toutefois de nombreux domaines ne respectent pas cette hypothèse. 
 - Les plans avec contingence permettent à l’agent d’observer le monde pendant l’exécution,  afin  de  choisir  quelle  branche  du  plan  suivre.  Dans  certains  cas,  la  planification sans capteurs, ou planification conformante, permet de construire des plans qui fonc donnent  sans  perception.  Les  plans  conformants  et  les  plans  avec  contingence  sont construits à partir d’une exploration dans l’espace des états de croyance. L’efficacité de la représentation ou du calcul des états de croyance est un problème capital. 
 - Un agent de planification en ligne utilise le monitoring de l’exécution et effectue les réparations nécessaires pour récupérer des situations inattendues, qui peuvent être dues à des actions non déterministes, des événements exogènes ou des modèles de l’environnement incorrects. 
 - La planification multiagent est nécessaire quand il existe dans l’environnement d’autres agents avec lesquels coopérer ou rivaliser. Ils peuvent construire des plans communs, mais il faut leur adjoindre une forme ou une autre de coordination si deux agents doivent s’entendre sur le plan à exécuter. 
 - Ce  chapitre  dépasse  la  planification  classique  pour  traiter  des  environnement  non déterministes  (dans  lesquels  les  résultats  des  actions  sont  incertains)  mais  ce  n’est pas notre dernier mot sur la planification. Le chapitre 17 décrit des techniques pour les environnements stochastiques (dans lequels des probabilités sont associées aux résultats des actions): les processus de décision de Markov, les processus de décision de Markov partiellement observables et la théorie des jeux. Au chapitre 21, nous montrons que l'apprentissage par renforcement permet à un agent d'apprendre à se comporter en tirant des leçons des réussites et des échecs.
 
 ...
 
 
 ## Chapitre 12 :
 
 #### Résumé
 
 
 En  détaillant  la  façon  de  représenter  une  diversité  de  connaissances,  nous  espérons avoir donné au lecteur une idée de la manière dont les bases de connaissances réelles sont construites,  et  des  intéressantes  questions  philosophiques  que  pose  la  représentation  des connaissances. Voici les principaux points abordés : 
 - La représentation des connaissances à grande échelle exige une ontologie générale qui organise et lie ensemble les différents domaines spécialisés des savoirs. 
 - Une ontologie générale doit couvrir une grande diversité de connaissances et être capable, en principe, de gérer n’importe quel domaine. 
 - La construction d une vaste ontologie générale présente d’importantes difficultés et reste à réaliser, bien que les bibliothèques actuelles semblent tout à fait robustes. 
 - Nous avons présenté une ontologie supérieure fondée sur des catégories et sur le calcul des événements. Nous avons abordé les catégories, les sous-catégories, les parties, les objets structurés, les mesures, les substances, les événements, l'espace et le temps, le changement et les croyances.
 - Les types naturels ne peuvent être définis complètement en logique, mais il est possible de représenter leurs propriétes
 - On peut représenter les actions, les évenements et le temps, soit en calcul des situtations, soit dans des représentations plus expressives telles que le calcul des événements et le calcul des fluents. De telles représentations permettent à un agent de construire des plans grâce à l'inférence logique. 
 - On peut représenter les états mentaux des agents par des chaînes qui dénotent des croyances
 - Nous avons présenté une analyse détaillée du domaine des achats sur Internet, afin de mettre en œuvre l’ontologie générale et de montrer comment un agent d’achat pouvait utiliser des connaissances propres à des domaines. 
 - Des systèmes de représentation spécialisés comme les réseaux sémantiques et les logiques de description ont été conçus pour aider a organiser une hiérarchie de catégories. 
 - L’héritage est une forme importante d’inférence qui permet de déduire les propriétés des objets à partir de leur appartenance à des catégories. 
 - L'hypothèse du monde clos, telle quelle est implémentée dans les programmes logiques, fournit un procédé simple pour éviter d énoncer un grand nombre d’informations sous forme négative. Le mieux est de la considérer comme spécifiant des valeurs par défaut susceptibles d’être redéfinies par de nouvelles informations. 
 - Les logiques non monotones telles que la circonscription et la logique des défauts sont destinées à saisir les raisonnements par défaut en général. 
 - Les systèmes de maintien de la vérité gèrent de manière efficace les mises à jour et les révisions des connaissances.

 ## Chapitre 13 :
 
 #### Résumé
 
 Ce chapitre fournit une introduction à la théorie des probabilités, laquelle permet de raisonner sur des données incertaines. 
 -  L’incertitude provient de la paresse et de l’ignorance. Il est impossible d’y échappe' dans des environnements complexes, non déterministes, ou encore partiellement observables
 -  Les probabilités expriment l’incapacité de l’agent à parvenir à une décision exacte quani à la vérité d’une proposition. Elles représente les croyances de l’agent, eu égard aux observations.
 -  La théorie de la décision associe les croyances et les aspirations de l’agent pour déterminer 1 action qui rend maximale Futilité escomptée. 
 -  Les assertions de probabilités de base comprennent les probabilités a priori et les probabilités conditionnellessur des propositions simples ou complexes. 
 -  Les axiomes de la théorie des probabilités restreignent les probabilités que l’on peut assignei à des propositions. Un agent qui enfreint ces axiomes se comportera de façon irrationnelle dans certaines conditions. 
 -  La distribution de probabilités conjointe complète spécifie la probabilité de chaque assignation complète de valeurs à des variables aléatoires. Sa taille est généralement trop importante pour qu’on puisse l’utiliser sous sa forme explicite. Cependant, quand sa taille est modérée, elle peut être utilisée pour obtenir la probabilité de toute proposition : on n’a alors qu'à additionner les entrées correspondant aux mondes possibles rendant vraie la proposition d’intérêt.
 -  L’indépendance  absolue  entre  deux  sous-ensembles  de  variables  aléatoires  permet  de factoriser  la  distribution  conjointe  complète  en  distributions  conjointes  plus  petites  et de réduire la complexité. En pratique, cependant, elle est rarement observée. 
 -  La règle de Bayes permet de calculer des probabilités inconnues à partir de probabilités conditionnelles connues, habituellement dans le sens causal. Comme dans le cas de distribution conjointe complète, son application à de trop nombreuses observations devient rapidement impossible. 
 -  L’indépendance conditionnelle due aux relations causales connues peut parfois permettre de factoriser la distribution conjointe complète en distributions conditionnelles plus petites Le modèle de Bayes naïf suppose l'indépendance conditionnelle de toutes les variables conséquences, étant donné la seule variable cause. Contrairement à un modèle arbitraire dont la complexité croît exponentiellement, un modèle de Bayes naif croît linéairement avec le nombre de variables conséquences.
 -  Un agent du monde du wumpus peut calculer les probabilités de faits non observés du monde et les exploiter pour prendre de meilleurs décisions qu'un agent purement logique
 
 ## Chapitre 14 :
 
 #### Résumé
 
 Ce chapitre a décrit les réseaux bayésiens, une représentation bien développée pour la représentation des connaissances incertaines. Les réseaux bayésiens jouent un rôle assez analogue à celui de la logique propositionnelle pour les connaissances définies : 
 - Un réseau bayésien est un graphe orienté acyclique dont les nœuds correspondent à des variables aléatoires ; chaque nœud a une distribution conditionnelle fonction de ses parents. 
 - Les réseaux bayésiens permettent de représenter les relations d’indépendance conditionnelle dans un domaine avec concision. 
 - Un réseau bayésien spécifie une distribution conjointe complète ; chaque entrée de la distribution conjointe est définie comme le produit des entrées correspondantes dans les distributions conditionnelles locales. 
 - Un réseau bayésien est souvent exponentiellement plus petit que la distribution conjointe donnée explicitement.
 
 -  On peut représenter de nombreuses distributions conditionnelles de manière compacte par des familles de distributions canoniques. Les réseaux bayésiens hybrides qui contiennent à la fois des variables continues et des variables discrètes, uti!isor différentes distributions canoniques. 
 -  L'inférence dans les réseaux bayésiens revient à calculer la distribution de probabi lités d’un ensemble de variables de requête, étant donné un ensemble de variables d'observation. Les algorithmes d’inférence exacte, comme l’algorithme d’élimination des variables, évaluent des sommes de produits de probabilités conditionnelles au efficacement que possible. 
 -  Dans les polyarbres (réseaux simplement connectés), l’inférence exacte deman ie temps linéaire en fonction de la taille du réseau. Dans le cas général, le problème est impraticable. 
 -  Les techniques d’approximation stochastiques telles que la pondération par la mai semblance et MCMC (chaîne de Markov Monte-Carlo) peuvent donner des estimatif raisonnables des vraies probabilités a posteriori dans un réseau et peuvent gérer d réseaux beaucoup plus grands que les algorithmes exacts. 
 -  On peut combiner la théorie des probabilités avec les possibilités de représentation la logique du premier ordre pour construire des systèmes très puissants capables raisonner dans l'incertitude. Les modèles probabilistes relationnels (MPR) adup des restrictions qui garantissent une distribution de probabilités exprimable dans réseau bayésien équivalent. Par ailleurs, les modèles probabilistes en univers ou* (MPUO) peuvent incorporer l'existence et Vincertitude d’identité en définissant. distributions de probabilités s’appliquant à l'espace infini des mondes possible premier ordre.
 -  Différents systèmes alternatifs de raisonnement dans l'incertitude ont été proposés. De manière générale, les systèmes vérifonctionnels ne sont pas bien adaptés à ce type de raisonnement. 

 ## Chapitre 15 :
 
 #### Résumé
 
 Ce chapitre a traité du problème général de la représentation et du raisonnement sur des processus temporels probabilistes. En voici les aspects essentiels : 
 -   Les changements d’état du monde sont gérés au moyen d’un ensemble de variables aléatoires qui représentent les états à chaque moment dans le temps. 
 -   On peut concevoir des représentations satisfaisant à la propriété de Markov, afin que «l’avenir soit indépendant du passé étant donné le présent». Si, en outre, on suppose que le processus est stationnaire 
 -   Autrement dit que sa dynamique ne change pas au fil du temps -, la représentation s’en trouve très simplifiée. 
 -   Un modèle probabiliste temporel contient un modèle de transition qui décrit l’évolution et un modèle de capteur qui décrit le processus d’observation. 
 -   Dans les modèles temporels, les principales tâches d’inférence sont le filtrage, la prédiction, le lissage et le calcul de l’explication la plus vraisemblable. Chacune d’elles peut être exécutée au moyen d’algorithmes récursifs simples, dont le temps d'exécution croît linéairement avec la longueur de la séquence. 
 -   Trois familles de modèles temporels ont été étudiées plus en détail : les modèles de Markov cachés, les filtres de Kahn an et les réseaux bayésiens dynamiques (dont les deux premiers sont des cas particuliers). 
 -   Sauf à émettre des hypothèses particulières, comme dans le cas des filtres de Kalman, on observe que l’inférence exacte en présence de nombreuses variables d’état se révèle impossible en pratique mais que l’algorithme de filtrage particulaire semble être un algorithme d’approximation efficace. 
 -   Lorsque l’on souhaite suivre la trajectoire de plusieurs objets, une nouvelle incertitude intervient liée à l’association de chaque observation à un objet donné : le problème de 1 association des données. Le nombre d hypothèses d’association est généralement tmP grand pour être énuméré, mais les algorithmes MCMC et de filtrage pour l’associatio'1 de données fonctionnent bien en pratique.

 ## Chapitre 16 :
 
 #### Résumé
 
 Ce chapitre montre comment combiner la théorie de l'utilité avec les probabilités pour permettre à un agent de sélectionner des actions qui maximiseront sa performance attendue :
 - La théorie des probabilités décrit ce qu'un agent devrait croire en s'appuyant sur l'observation. La théorie de l'utilité décrit ce que veut un agent, et la théorie de la décision synthétise les deux pour décrire ce que l'agent devrait faire.
 - On peut exploiter la théorie de la décision pour construire un système qui prend des décisions en considérant toutes les
 -  La théorie de l'utilité montre qu’on peut décrire un agent dont les préférences entre des loteries sont cohéientes avec un ensemble d’axiomes simples comme possédant une fonction d'utilité ; de plus, l'agent sélectionne les actions comme si elles maximisaient son utilité espérée. 
 -  La théorie de Futilité multiattribut traite des utilités qui dépendent de plusieurs attributs d’états distincts. La dominance stochastique est une technique particulièrement utile qui permet de prendre des décisions dépourvues d’ambiguïté, même en l’absence de valeurs d’utilité précises pour les attributs. 
 -  Les réseaux de décision fournissent un formalisme simple pour exprimer et résoudre des problèmes de décision. Ils constituent une extension naturelle des réseaux bayésiens, contenant des nœuds de décision et des nœuds d’utilité en plus des nœuds de hasard.
 -  Il arrive que le résolution d'un problème nécessite de trouver des informations supplémentaires avant de pouvoir prendre une décision. On définit la valeur de l'information comme l'amélioration de l'utilité par rapport à la prise de décisions en l'absence de l'information.
 -  Les systèmes experts qui incorporent l'utilité ont plus de capacités que les systèmes à base d'inférence pure. Outre le fait qu'ils sont capables de prendre des décisions, ils peuvent utiliser la valeur de l'information pour décider quelles poser, ils peuvent dresser des plans de contingence et, enfin, ils peuvent calculer la sensibilité de leur décision à de petites modifications apportées aux évaluations de probabilités et des utilités.

 ## Chapitre 17 : 
 
 #### Résumé
 
 Ce chapitie explique comment exploiter les connaissances dont on dispose sur le monde pour prendre des décisions, même quand les résultats des actions sont incertains et que les récompenses associées à celles-ci ne seront peut-être récoltées que beaucoup plus tard. Les principaux points sont les suivants : 
 - Les problèmes de décision séquentiels dans les environnements incertains, également nommés processus de décision markoviens, ou PDM, sont définis par un modèle de transition qui spécifie les résultats probabilistes des actions, et par une fonction de récompense, qui spécifie la récompense dans chaque état. 
 - L'utilité d’une séquence d’états est la somme de toutes les récompenses sur la séquence, éventuellement escomptées dans le temps. La solution d’un PDM est une politique qui associe une décision à chaque état que l’agent pourrait atteindre. Une politique optimale maximise l’utilité des séquences d’états rencontrées quand elle est exécutée. 
 - L’utilité d’un état est l’utilité espérée des séquences d’états rencontrées quand une politique optimale est exécutée en partant de cet état. Dans un PDM, l'algorithme d’itération de la valeur fonctionne en résolvant itérativement les équations reliant l'utilité de chaque état à celle de ses voisins.
 - L'algorithme d'itération de la politique alterne entre le calcul de l'utilité des états avec la politique courante et l'amélioration de cette politique par rapport aux utilités courantes.
- Les PDM partiellement observables, ou PDMPO, sont beaucoup plus difficiles à résoudre que les PDM. Pour ce faire, on peut les convertir en PDM dans l'espace continu des états de croyance, on a conçu les deux algorithmes d'itération de la valeur et de la politique. Dans une PDMPO, un comportement optimal nécessite de recueillir des informations afin de réduire l'incertitude et donc de prendre de meilleures décisions à l'avenir.
- On peut construire des agents utilisant la théorie de la décision pour les environnements à PDMPO. Il se servent d'un réseuau de décision dynamique pour représenter le modèle de transition et le modèle de capteurs, mettre à jour son état de croyance et projeter en avant les séquences d'actions possibles
- La théorie des jeux décrit le comportmement rationnel d'agents se trouvant dans des situations dans lesquelles plusieurs agents interagissent simultanément. Les solutions des jeux sont des équilibres de Nash - des profils stratégiques dans lesquels aucun agent n'a de motif de dévier de la stratégie spécifiée.
- La conception de mécanismes peut servir à fixer les règles selon lesquells les agents interagiront, afin de maximiser une utilité globale grâce aux opérations d'agents individuellement rationnels. Ils existe parfois certains mécanismes qui atteignent ce but sans que chaque agent ait besoin de considérer les choix des autres

Nous reviendrons au monde des PDM et des PDMPO au chapitre 21, quand nous étudierons les méthodes d'apprentissage par renforcement qui permettent à un agent d'améliorer son comportement à partir de l'expérience dans des environnements séquentiels et incertains.

 ## Chapitre 18 :
 #### Résumé
 

 On a présenté dans ce chapitre l’apprentissage inductif de fonctions à partir d exemple Les principaux points abordés ont été les suivants : 
 -  L’apprentissage peut prendre beaucoup de formes différentes selon la nature de I agen du composant à améliorer et du retour d’expérience disponible. 
 -  Si  le  retour  disponible  indique  la  réponse  correcte  pour  des  exemples  d  entrées,  le problème d’apprentissage s’appelle de l’apprentissage supervisé. Le problème est d apprendre une fonction y = h{x). On appelle classification 1 apprentissage d une fonctior à valeur discrète et régression celui d’une fonction continue. 
 -  L’apprentissage inductif implique de trouver une hypothèse qui coïncide bien avec exemples. Le rasoir d’Occam suggère de choisir l’hypothèse cohérente la plus simp; La difficulté de cette tâche dépend de la représentation choisie. -  Les arbres de décision peuvent représenter toutes les fonctions booléennes. L'heur tique du gain d’information fournit une méthode efficace pour trouver un arbre décision simple et cohérent. 
 -  La performance d’un algorithme d’apprentissage se mesure par sa courbe d’appr- tissage qui donne la précision de la prédiction sur l’ensemble de test en fonction de taille de l’ensemble d’apprentissage. 
 -  Lorsqu’il existe le choix entre plusieurs modèles, on peut recourir à la validation croisé pour choisir un modèle qui va bien généraliser. 
 -  Toutes les erreurs ne sont pas toujours égales. Une fonction de perte indique à T point une erreur est nuisible ; le but est de rendre cette perte minimale sur un enseiri11 de validation.
 -  La théorie algorithmique de ï apprentissage analyse la complexité d’échantillu^ et la complexité calculatoire de l’apprentissage inductif. Il existe un compron11*elU l’expressivité du laneaae des hvnnthÀc^c u 
 -  La régression linéaire est un modèle largement répandu. On peut trouver les paramètres optimaux de la regression linéaire par descente du gradient, ou en faire le calcul exact.
 -  Un classificateur linéaire avec un seuil dur, aussi appelé perceptron, peut être entrainé par une règle simple d'adaptation des poids pour représenter des données qui sont linéairement séparables. Dans le cas contraire, la règle ne converge pas.
 -  Dans la régression logistique, le seuil dur du perceptron est remplacé par un seuil doux défini par une fonction logistique. La méthode de descente du gradient fonctionne bien, même pour des données comprenant beaucoup de bruit et non linéairement séparables.
 -  les réseaux de neurones représentent des fonctions non linéaires complexes au moyen d'un réseau d’unités à seuil linéaire. Les réseaux de neurones feed-forward à plusieurs couches peuvent représenter toute fonction, pourvu qu’ils contiennent assez d’unités. L algorithme de rétropropagation implémente une méthode de descente du gradient dans un espace de paramètres pour minimiser l’erreur de sortie.
 -  Les modèles non paramétriques utilisent toutes les données pour chaque prédicuon plutôt que d’essayer de résumer d’abord les données au moyen d’un petit nombre de paramètres. Au nombre de ces modèles comptent la méthode des plus proches voisins t la régression pondérée localement. 
 -  Les machines à vecteurs de support trouvent des séparateurs linéaires avec marge maximale pour améliorer la performance en généralisation du classificateur Le - mé­ thodes à noyau transforment implicitement les données d’entrée en un espace de Plus grande dimension où l’on peut trouver un séparateur linéaire même ies données d'origine ne sont pas séparables.
 -  Les méthodes d'ensemble comme le dopage ont souvent de meilleurs performances que les méthodes individuelles. Dans l'apprentissage en ligne, on peut agréger des opinions d'experts pour apporcher d'aussi près que possible de la performance d'expert optimale même lorsque les données suivent une loi de probabilité qui varie
 
 ## Chapitre 19 :
 
 #### Résumé
 
 Les méthodes d’apprentissage statistique vont du simple calcul de moyennes à la construc­ tion de modèles complexes, tels que les réseaux bayésiens. Elles ont de nombreuses applica­ tions en informatique, en sciences de l’ingénieur, en bioinformatique, dans les neurosciences, en psychologie et en physique. Ce chapitre a présenté certaines notions de base et donné un aperçu des iondements mathématiques : — Les méthodes d apprentissage bayesien toimulent l’apprentissage comme une forme d inférence piobabiliste, qui utilise les obseï valions pour actualiser une distribution n pi ioi i sur les hypothèses. Cette appioche iouinit un bon moyen pour implénientei h
 
 nécessiteront la gestion d’environnements partiellement observables, continus et de grande dimension, dans lesquels les comportements peuvent faire appel à des milliers, voire des millions d'actions primitives.
 ## Chapitre 20 :
 
 #### Résumé
 
 Ce chapitre a examiné la question de l’apprentissage par renforcement : comment un agent peut-il  devenir  performant  dans  un  environnement  inconnu,  à  l'aide  de  ses  seuls  percepts et  de  récompenses  occasionnelles?  On  peut  considérer  l’apprentissage  par  renforcement comme un microcosme dans le problème global de l’IA, mais il a été étudié dans un certain nombre de contextes simplifiés pour faciliter la progression : -  La conception globale de l’agent dicte le type d'information qu'il y a lieu d'apprendre. Nous avons abordé trois grandes conceptions d’agents : la conception à base de modèle, qui utilise un modèle P et une fonction d’utilité U ; la conception sans modèle, qui utilise une fonction action-valeur-Q ; et la conception réflexe, qui utilise une politique n. -  Trois approches permettent d’apprendre les utilités : 1. L’estimation directe de Futilité utilise la récompense totale espérée pour un état donné comme observation directe pour apprendre son utilité. 2.  La programmation dynamique adaptative (PDA) apprend un modèle et une fonc­ tion de récompense, puis utilise une itération sur la valeur ou sur la politique pour obtenir les utilités ou une politique optimale. La PDA fait un usage optimal des contraintes locales imposées aux utilités des états par la structure de voisinage de l’environnement.
 
 pour qu’elles correspondent à celles des états successeurs. On peut voir comme des approximations de l’approche PDA, dans lesquelles le processus d’apprentissage ne nécessite pas de modèle. Le recours à un modèle appris pour générer des pseudo-expériences peut toutefois permettre d’apprendre plus vite Les fonctions de valeur, ou fonctions-Q, peuvent être apprises par une approche PDA ou une approche TD. Avec 1 approche TD, le Q leca nnig ne nécessite aucun modèle phase d’apprentissage ou de sélection d’action. Cela simplifie le problème de l’appren tissage mais réduit la capacité à apprendre dans des environnements complexes parce que l’agent ne peut pas simuler les résultats des différentes lignes de conduite possibles Quand l’agent est responsable de la sélection des actions lors de l’apprentissage
 
 méthodes  de  différence  temporelle  (TD)  mettent  a  jour  les  estimai tés  pour  qu  elles  correspondent  à  celles  des  états  successeurs.  On comme des approximations de l’approche PDA. dans lesquelles le p turent issage ne nécessite pas de modèle. Le recours a un modèle ap| 
gent est responsable de la sélection des actions lors de l’apprentissage, il face à un choix entre la valeur estimée de ces actions et le potentiel que 
représente    apprentissage de nouvelles informations utiles. Une solution exacte au | 
loration est impossible, mais certaines heuristiques donnent des résuit raisonnables. Dans les grands espaces d’états, les algorithmes d apprentissage par renforcement doivent utiliser une représentation fonctionnelle approchée pour pouvoir généralise) sur les états. On peut utiliser le signal de différence temporelle directement pour mettre à jour les paramètres dans des représentations telles que les réseaux de neurones. Les méthodes de recherche de politique opèrent directement sur une représentation de la politique, en essayant de l’améliorer en tenant compte de la performance observée, w variation de la performance dans un domaine stochastique constitue un problème diffi­ cile ; dans les domaines simulés, on peut le résoudre en fixant à l’avance des séquences 

î qu’il permet d’éliminer le codage manuel des stratégies de contrôle, l’apprentissage enforcement continue à être l’un des domaines les plus actifs de la recherche en appren' ge artificiel. Les applications à la robotique sont particulièrement prometteuses ; eH 

 ## Chapitre 21 :
 
 #### Résumé
 
 Les principaux points de ce chapitre sont les suivants : Les  modèles  de  langage  probabilistes  basés  sur  les  «-grammes  récupèrent  un  volume surprenant  d’informations  sur  une  langue.  Ils  se  comportent  bien  dans  diverses  tâches, telles que l’identification de la langue, la correction orthographique, la classification en genres et la reconnaissance d’entités nommées. Ces modèles de langage pouvant avoir des millions de caractéristiques, la sélection de celles-ci et le prétraitement des données pour réduire le bruit sont importants. Pour la classification de textes, on peut employer des modèles de Bayes naïfs comme les n-grammes, ou l’un quelconque des algorithmes de classification étudiés précédeni- ment.  La  classification  peut  également  être  vue  comme  un  problème  de  compression des données. Les systèmes de recherche d’informations utilisent un modèle de langage très simple basé sur des sacs de mots, tout en parvenant à obtenir de bonnes performances en termes de rappel et de précision sur de très grands corpus de textes. Sur les corpus du Web, les algorithmes d’analyse des liens améliorent la performance. Les  tâches  de  questions-réponses  peuvent  être  traitées  par  une  approche  fondée  su la  techerche  d  informations,  pour  les  questions  qui  ont  plusieurs  réponses  dans  h corpus. Quand le corpus contient plus de réponses, on peut utiliser des techniques qu privilégient la précision par rapport au rappel
 
 Les systèmes d'extraction d'informations utilisent un modèle plus complexe qui comprend des notions de syntaxe et de sémantique limitées. On peut les construire avec des automates à états finis, des MMC ou des champs conditionnels aléatoires, et il peuvent être appris à partir d'exemples
 Pour construire un système de traitement de langage statistique, mieux vaut mettre au point un modèle capable de faire bon usage des données disponibles, même s'il semble exagérement simple.
 
 ## Chapitre 22 :
 
 #### Résumé
 
 Les phrases d‘un langage hors contexte peuvent être analysées en un lui par un analyseur tabulaire tel que Lalgorithme CYK, qui nécessite que grammaire soient en forme normale de Chomsky. On peut utiliser un corpus arboré pour apprendre une grammaire. Il est egalement 
possible d’apprendre une grammaire à partir d’un corpus de phrases non analyse, mais avec moins de succès. Une PCFG lexicalisée permet de représenter le fait que certaines relations entre dus mots sont plus courantes que d’autres. 11 est intéressant d’augmenter les grammaires pour traiter des problèmes mis que l'ac cord sujet-verbe et le cas du pronom. Une grammaire h clauses définies (I )C( •) est un 
formalisme qui autorise de telles augmentations. La IXXi permet d'ulilisi 
logique pour l’analyse syntaxique, l’interprétation sémantique (et même la  géii 
de langage). Une grammaire augmentée peut également gérer l’interprétation sémantique. L’ambiguïté est un problème très important en traitement du langage naturel ; de 1res nombreuses phrases ont plusieurs interprétations possibles, dont généralement une seule est appropriée. La désambiguïsation s’appuie sur une connaissance du monde, de la situation courante et de l’emploi de la langue. 
On a implémenté des systèmes de traduction automatique en utilisant tout 
de techniques, de l’analyse syntaxique et sémantique complète a des méthodes stalb 
tiques fondées sur les fréquences des expressions. Actuellement, les modèles 
sont les plus répandus et les plus performants. Les systèmes de reconnaissance de la parole s’appuient égaleme principes statistiques. Les systèmes de reconnaissance vocale so même s’ils sont encore imparfaits. 
 ## Chapitre 23 :
 
 #### Résumé
 
 
 par un test comportemental. Il a anticipé de nombreuses objections a a p machines pensantes. Peu de chercheurs en IA prêtent attention au test de Turing. 1 s préfèrent se concentrer sur les performances de leurs systèmes appliqués à des tâches pratiques plutôt que sur leur capacité à imiter les humains. A notre époque, on s’accorde généralement à penser que les états mentaux sont des états du cerveau. L< s arguments pour et contre 1 LA forte ne sont pas concluants. Dans le courant doini- nant, les chercheurs sont peu nombreux à penser que quoi que ce soit de significatif dépende du résultat du débat. i. i conscience demeure un mystère 
 ## Chapitre 24 :
 
 #### Résumé
 ## Chapitre 25 :
 #### Résumé
 
 ## Chapitre 26 :
 #### Résumé


 

 
_____ 
 

 
 
 ---

---

